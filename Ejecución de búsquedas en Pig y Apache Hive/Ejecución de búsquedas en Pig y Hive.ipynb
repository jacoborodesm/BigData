{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plantilla para la Tarea online BDA03\n",
    "\n",
    "# Nombre del alumno: Jacobo Rodríguez Esmorís\n",
    "\n",
    "Realiza las tareas que se plantean en cada ejercicio. En algunas tareas deberás completar las celdas que están incompletas en otras añadir nuevas celdas. Se trata de que implementes una serie de consultas con HQL (Hive) y Pig Latin.\n",
    "\n",
    "Vamos a seguir utilizando el `dataset` de retrasos en vuelos en EEUU de la guía práctica. A modo de recordatorio, en el siguiente apartado, repetimos la explicación del significado de los campos.\n",
    "\n",
    "# Dataset de retrasos en vuelos\n",
    "\n",
    "Vamos a usar [este](https://www.kaggle.com/datasets/tylerx/flights-and-airports-data) de Kaggle\n",
    "para aprender a usar tanto Hive como Pig. Kaggle es un sitio muy popular en ciencia de datos. En este sitio los científicos de datos pueden publicar y compartir sus trabajos. Además también se pueden proponer concursos en los que los participantes compiten en la construcción del mejor modelo para el problema propuesto.\n",
    "\n",
    "El `dataset` contiene información sobre retrasos en vuelos en EEUU. Hay dos ficheros de interés: `airports.csv` y `flights.csv`.\n",
    "\n",
    "El primero tiene información sobre los aeropuertos y consta de los siguientes campos:\n",
    "   * airport_id: identificador del aeropuerto. Numérico, aunque se utilizará un campo `string` en Hive.\n",
    "   * city: ciudad del aeropuerto.\n",
    "   * state: estado del aeropuerto.\n",
    "   * name: nombre del aeropuerto.\n",
    "   \n",
    "El fichero `flights` tiene la siguiente estructura:\n",
    "   * DayofMonth: día del mes del vuelo.\n",
    "   * DayOfWeek: día de la semana del vuelo.\n",
    "   * Carrier: Identificador de la compañía aérea.\n",
    "   * OriginAirportID: Identificador del aeropuerto de origen.\n",
    "   * DestAirportID: Identificador del aeropuerto de destino.\n",
    "   * DepDelay: Minutos de retraso en la salida de un vuelo (puede ser negativo si el vuelo sale antes de lo previsto).\n",
    "   * ArrDelay: Minutos de retraso en la llegada de un vuelo (puede ser negativo si el vuelo sale antes de lo previsto).\n",
    "\n",
    "El directorio `notebooks` contiene el `archiv.zip` con los dos ficheros. Para descargarlo de Kaggle hay que estar registrado y se ha incluido para que no tengas que registrarte."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.- Realiza el proceso de preparación que se hizo en la guia práctica:\n",
    "\n",
    "* Crea las celdas y muestra el resultado de su ejecución de la extracción de los ficheros del `dataset` de vuelos.\n",
    "* Crea la base de datos de Hive y las tablas `airports` y `flights`. Presta atención a cambiar los comentarios y no simplemente copiar los de la guía.\n",
    "* Carga las tablas y crea consultas de HQL que muestren 10 aeropuertos y 10 vuelos como se hizo en la guía práctica.\n",
    "* Crea un `script` en Pig Latin que muestre 10 aeropuertos y 10 vuelos como se hizo en la guía práctica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get:1 http://archive.ubuntu.com/ubuntu focal InRelease [265 kB]\n",
      "Get:2 http://security.ubuntu.com/ubuntu focal-security InRelease [114 kB]\n",
      "Get:3 http://archive.ubuntu.com/ubuntu focal-updates InRelease [114 kB][33m\u001b[33m\n",
      "Get:4 http://archive.ubuntu.com/ubuntu focal-backports InRelease [108 kB][33m\u001b[33m\u001b[33m\u001b[33m\n",
      "Get:5 http://security.ubuntu.com/ubuntu focal-security/universe amd64 Packages [1171 kB]\n",
      "Get:6 http://archive.ubuntu.com/ubuntu focal/universe amd64 Packages [11.3 MB]3m\n",
      "Get:7 http://archive.ubuntu.com/ubuntu focal/restricted amd64 Packages [33.4 kB][0m\u001b[33m\n",
      "Get:8 http://security.ubuntu.com/ubuntu focal-security/main amd64 Packages [3329 kB]\n",
      "Get:9 http://archive.ubuntu.com/ubuntu focal/multiverse amd64 Packages [177 kB]\u001b[0m\u001b[33m\n",
      "Get:10 http://archive.ubuntu.com/ubuntu focal/main amd64 Packages [1275 kB]    \u001b[0m\u001b[33m\u001b[33m\n",
      "Get:11 http://archive.ubuntu.com/ubuntu focal-updates/multiverse amd64 Packages [32.4 kB][33m\u001b[33m\n",
      "Get:12 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 Packages [3806 kB]\u001b[33m\n",
      "Get:13 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 Packages [1467 kB]m33m\u001b[33m\u001b[33m\n",
      "Get:14 http://archive.ubuntu.com/ubuntu focal-updates/restricted amd64 Packages [3345 kB][33m\u001b[33m\n",
      "Get:15 http://security.ubuntu.com/ubuntu focal-security/multiverse amd64 Packages [29.7 kB]\n",
      "Get:16 http://security.ubuntu.com/ubuntu focal-security/restricted amd64 Packages [3196 kB]\n",
      "Get:17 http://archive.ubuntu.com/ubuntu focal-backports/universe amd64 Packages [28.6 kB][33m\n",
      "Get:18 http://archive.ubuntu.com/ubuntu focal-backports/main amd64 Packages [55.2 kB]33m\n",
      "Fetched 29.9 MB in 12s (2482 kB/s)                                             \u001b[0m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "207 packages can be upgraded. Run 'apt list --upgradable' to see them.\n"
     ]
    }
   ],
   "source": [
    "! apt update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "Suggested packages:\n",
      "  zip\n",
      "The following NEW packages will be installed:\n",
      "  unzip\n",
      "0 upgraded, 1 newly installed, 0 to remove and 207 not upgraded.\n",
      "Need to get 168 kB of archives.\n",
      "After this operation, 593 kB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 unzip amd64 6.0-25ubuntu1.1 [168 kB]\n",
      "Fetched 168 kB in 1s (259 kB/s)[0m\u001b[33m\n",
      "debconf: delaying package configuration, since apt-utils is not installed\n",
      "\n",
      "\u001b7\u001b[0;23r\u001b8\u001b[1ASelecting previously unselected package unzip.\n",
      "(Reading database ... 43749 files and directories currently installed.)\n",
      "Preparing to unpack .../unzip_6.0-25ubuntu1.1_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  0%]\u001b[49m\u001b[39m [..........................................................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 20%]\u001b[49m\u001b[39m [###########...............................................] \u001b8Unpacking unzip (6.0-25ubuntu1.1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 40%]\u001b[49m\u001b[39m [#######################...................................] \u001b8Setting up unzip (6.0-25ubuntu1.1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 60%]\u001b[49m\u001b[39m [##################################........................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 80%]\u001b[49m\u001b[39m [##############################################............] \u001b8Processing triggers for mime-support (3.64ubuntu1) ...\n",
      "\n",
      "\u001b7\u001b[0;24r\u001b8\u001b[1A\u001b[J"
     ]
    }
   ],
   "source": [
    "! apt install unzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  archive.zip\n",
      "  inflating: airports.csv            \n",
      "  inflating: flights.csv             \n"
     ]
    }
   ],
   "source": [
    "! unzip -j -o archive.zip airports.csv flights.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "366 airports.csv\r\n",
      "airport_id,city,state,name\r",
      "\r\n",
      "10165,Adak Island,AK,Adak\r",
      "\r\n",
      "10299,Anchorage,AK,Ted Stevens Anchorage International\r",
      "\r\n",
      "10304,Aniak,AK,Aniak Airport\r",
      "\r\n",
      "10754,Barrow,AK,Wiley Post/Will Rogers Memorial\r",
      "\r\n",
      "10551,Bethel,AK,Bethel Airport\r",
      "\r\n",
      "10926,Cordova,AK,Merle K Mudhole Smith\r",
      "\r\n",
      "14709,Deadhorse,AK,Deadhorse Airport\r",
      "\r\n",
      "11336,Dillingham,AK,Dillingham Airport\r",
      "\r\n",
      "11630,Fairbanks,AK,Fairbanks International\r",
      "\r\n"
     ]
    }
   ],
   "source": [
    "! wc -l airports.csv && head airports.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2702219 flights.csv\r\n",
      "DayofMonth,DayOfWeek,Carrier,OriginAirportID,DestAirportID,DepDelay,ArrDelay\r",
      "\r\n",
      "19,5,DL,11433,13303,-3,1\r",
      "\r\n",
      "19,5,DL,14869,12478,0,-8\r",
      "\r\n",
      "19,5,DL,14057,14869,-4,-15\r",
      "\r\n",
      "19,5,DL,15016,11433,28,24\r",
      "\r\n",
      "19,5,DL,11193,12892,-6,-11\r",
      "\r\n",
      "19,5,DL,10397,15016,-1,-19\r",
      "\r\n",
      "19,5,DL,15016,10397,0,-1\r",
      "\r\n",
      "19,5,DL,10397,14869,15,24\r",
      "\r\n",
      "19,5,DL,10397,10423,33,34\r",
      "\r\n"
     ]
    }
   ],
   "source": [
    "! wc -l flights.csv && head flights.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 items\r\n",
      "-rw-r--r--   3 root supergroup      16308 2024-01-29 12:08 /user/root/flights/airports.csv\r\n",
      "-rw-r--r--   3 root supergroup   72088113 2024-01-29 12:08 /user/root/flights/flights.csv\r\n"
     ]
    }
   ],
   "source": [
    "! hdfs dfs -mkdir -p /user/root/flights/\n",
    "! hdfs dfs -put -f ./airports.csv /user/root/flights/\n",
    "! hdfs dfs -put -f ./flights.csv /user/root/flights/\n",
    "! hdfs dfs -ls /user/root/flights/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HIVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to jdbc:hive2://localhost:10000\n",
      "Connected to: Apache Hive (version 3.1.2)\n",
      "Driver: Hive JDBC (version 3.1.2)\n",
      "Transaction isolation: TRANSACTION_REPEATABLE_READ\n",
      "INFO  : Compiling command(queryId=root_20240129121703_e3045057-84ce-4532-8786-d8395096b101): SHOW DATABASES\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Semantic Analysis Completed (retrial = false)\n",
      "INFO  : Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:database_name, type:string, comment:from deserializer)], properties:null)\n",
      "INFO  : Completed compiling command(queryId=root_20240129121703_e3045057-84ce-4532-8786-d8395096b101); Time taken: 0.921 seconds\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Executing command(queryId=root_20240129121703_e3045057-84ce-4532-8786-d8395096b101): SHOW DATABASES\n",
      "INFO  : Starting task [Stage-0:DDL] in serial mode\n",
      "INFO  : Completed executing command(queryId=root_20240129121703_e3045057-84ce-4532-8786-d8395096b101); Time taken: 0.035 seconds\n",
      "INFO  : OK\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "+----------------+\n",
      "| database_name  |\n",
      "+----------------+\n",
      "| default        |\n",
      "+----------------+\n",
      "1 row selected (1.247 seconds)\n",
      "Beeline version 3.1.2 by Apache Hive\n",
      "Closing: 0: jdbc:hive2://localhost:10000\n"
     ]
    }
   ],
   "source": [
    "! beeline -u \"jdbc:hive2://localhost:10000\" -e \"SHOW DATABASES\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to jdbc:hive2://localhost:10000/\n",
      "Connected to: Apache Hive (version 3.1.2)\n",
      "Driver: Hive JDBC (version 3.1.2)\n",
      "Transaction isolation: TRANSACTION_REPEATABLE_READ\n",
      "INFO  : Compiling command(queryId=root_20240129122052_e2f14897-bde7-41aa-b3d7-4f9c73024191): CREATE DATABASE IF NOT EXISTS bda03  COMMENT 'Base de datos de la unidad BDA03'  WITH DBPROPERTIES ('Creada por' = 'Jacobo Rodr?guez', 'Fecha' = '29/01/2024')\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Semantic Analysis Completed (retrial = false)\n",
      "INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)\n",
      "INFO  : Completed compiling command(queryId=root_20240129122052_e2f14897-bde7-41aa-b3d7-4f9c73024191); Time taken: 0.043 seconds\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Executing command(queryId=root_20240129122052_e2f14897-bde7-41aa-b3d7-4f9c73024191): CREATE DATABASE IF NOT EXISTS bda03  COMMENT 'Base de datos de la unidad BDA03'  WITH DBPROPERTIES ('Creada por' = 'Jacobo Rodr?guez', 'Fecha' = '29/01/2024')\n",
      "INFO  : Starting task [Stage-0:DDL] in serial mode\n",
      "INFO  : Completed executing command(queryId=root_20240129122052_e2f14897-bde7-41aa-b3d7-4f9c73024191); Time taken: 0.166 seconds\n",
      "INFO  : OK\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "No rows affected (0.27 seconds)\n",
      "Beeline version 3.1.2 by Apache Hive\n",
      "Closing: 0: jdbc:hive2://localhost:10000/\n"
     ]
    }
   ],
   "source": [
    "! beeline -u \"jdbc:hive2://localhost:10000/\" -e \"\\\n",
    "CREATE DATABASE IF NOT EXISTS bda03 \\\n",
    "COMMENT 'Base de datos de la unidad BDA03' \\\n",
    "WITH DBPROPERTIES ('Creada por' = 'Jacobo Rodríguez', 'Fecha' = '29/01/2024');\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to jdbc:hive2://localhost:10000/bda03\n",
      "Connected to: Apache Hive (version 3.1.2)\n",
      "Driver: Hive JDBC (version 3.1.2)\n",
      "Transaction isolation: TRANSACTION_REPEATABLE_READ\n",
      "INFO  : Compiling command(queryId=root_20240129122942_8c1c3745-ee31-437d-849c-3ee5c5225c6d): DROP TABLE IF EXISTS airports\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Semantic Analysis Completed (retrial = false)\n",
      "INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)\n",
      "INFO  : Completed compiling command(queryId=root_20240129122942_8c1c3745-ee31-437d-849c-3ee5c5225c6d); Time taken: 0.098 seconds\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Executing command(queryId=root_20240129122942_8c1c3745-ee31-437d-849c-3ee5c5225c6d): DROP TABLE IF EXISTS airports\n",
      "INFO  : Starting task [Stage-0:DDL] in serial mode\n",
      "INFO  : Completed executing command(queryId=root_20240129122942_8c1c3745-ee31-437d-849c-3ee5c5225c6d); Time taken: 0.031 seconds\n",
      "INFO  : OK\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "No rows affected (0.171 seconds)\n",
      "INFO  : Compiling command(queryId=root_20240129122942_f5082f87-bead-40cb-894a-c9076891f1c0): CREATE EXTERNAL TABLE IF NOT EXISTS airports (airportid STRING, city STRING, state STRING, airportname STRING)  COMMENT 'USA Airports'  ROW FORMAT DELIMITED FIELDS TERMINATED BY '\\,'  TBLPROPERTIES ('Autor' = 'Jacobo Rodr?guez', 'Fecha' = '29/01/2024', 'skip.header.line.count'='1')\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Semantic Analysis Completed (retrial = false)\n",
      "INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)\n",
      "INFO  : Completed compiling command(queryId=root_20240129122942_f5082f87-bead-40cb-894a-c9076891f1c0); Time taken: 0.125 seconds\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Executing command(queryId=root_20240129122942_f5082f87-bead-40cb-894a-c9076891f1c0): CREATE EXTERNAL TABLE IF NOT EXISTS airports (airportid STRING, city STRING, state STRING, airportname STRING)  COMMENT 'USA Airports'  ROW FORMAT DELIMITED FIELDS TERMINATED BY '\\,'  TBLPROPERTIES ('Autor' = 'Jacobo Rodr?guez', 'Fecha' = '29/01/2024', 'skip.header.line.count'='1')\n",
      "INFO  : Starting task [Stage-0:DDL] in serial mode\n",
      "INFO  : Completed executing command(queryId=root_20240129122942_f5082f87-bead-40cb-894a-c9076891f1c0); Time taken: 0.397 seconds\n",
      "INFO  : OK\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "No rows affected (0.533 seconds)\n",
      "Beeline version 3.1.2 by Apache Hive\n",
      "Closing: 0: jdbc:hive2://localhost:10000/bda03\n"
     ]
    }
   ],
   "source": [
    "! beeline -u \"jdbc:hive2://localhost:10000/bda03\" -e \"\\\n",
    "DROP TABLE IF EXISTS airports; \\\n",
    "CREATE EXTERNAL TABLE IF NOT EXISTS airports (airportid STRING, city STRING, state STRING, airportname STRING) \\\n",
    "COMMENT 'USA Airports' \\\n",
    "ROW FORMAT DELIMITED FIELDS TERMINATED BY '\\,' \\\n",
    "TBLPROPERTIES ('Autor' = 'Jacobo Rodríguez', 'Fecha' = '29/01/2024', 'skip.header.line.count'='1');\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to jdbc:hive2://localhost:10000/bda03\n",
      "Connected to: Apache Hive (version 3.1.2)\n",
      "Driver: Hive JDBC (version 3.1.2)\n",
      "Transaction isolation: TRANSACTION_REPEATABLE_READ\n",
      "INFO  : Compiling command(queryId=root_20240129123049_2506c397-541f-42ba-8eb3-ad889409e3a7): SELECT * FROM airports\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Semantic Analysis Completed (retrial = false)\n",
      "INFO  : Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:airports.airportid, type:string, comment:null), FieldSchema(name:airports.city, type:string, comment:null), FieldSchema(name:airports.state, type:string, comment:null), FieldSchema(name:airports.airportname, type:string, comment:null)], properties:null)\n",
      "INFO  : Completed compiling command(queryId=root_20240129123049_2506c397-541f-42ba-8eb3-ad889409e3a7); Time taken: 1.199 seconds\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Executing command(queryId=root_20240129123049_2506c397-541f-42ba-8eb3-ad889409e3a7): SELECT * FROM airports\n",
      "INFO  : Completed executing command(queryId=root_20240129123049_2506c397-541f-42ba-8eb3-ad889409e3a7); Time taken: 0.001 seconds\n",
      "INFO  : OK\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "+---------------------+----------------+-----------------+-----------------------+\n",
      "| airports.airportid  | airports.city  | airports.state  | airports.airportname  |\n",
      "+---------------------+----------------+-----------------+-----------------------+\n",
      "+---------------------+----------------+-----------------+-----------------------+\n",
      "No rows selected (1.276 seconds)\n",
      "Beeline version 3.1.2 by Apache Hive\n",
      "Closing: 0: jdbc:hive2://localhost:10000/bda03\n"
     ]
    }
   ],
   "source": [
    "! beeline -u \"jdbc:hive2://localhost:10000/bda03\" -e \"\\\n",
    "SELECT * FROM airports;\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to jdbc:hive2://localhost:10000/bda03\n",
      "Connected to: Apache Hive (version 3.1.2)\n",
      "Driver: Hive JDBC (version 3.1.2)\n",
      "Transaction isolation: TRANSACTION_REPEATABLE_READ\n",
      "INFO  : Compiling command(queryId=root_20240129124713_86eb1b6c-592d-4b01-b6ae-668c98fafcc2): DROP TABLE IF EXISTS flights\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Semantic Analysis Completed (retrial = false)\n",
      "INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)\n",
      "INFO  : Completed compiling command(queryId=root_20240129124713_86eb1b6c-592d-4b01-b6ae-668c98fafcc2); Time taken: 0.014 seconds\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Executing command(queryId=root_20240129124713_86eb1b6c-592d-4b01-b6ae-668c98fafcc2): DROP TABLE IF EXISTS flights\n",
      "INFO  : Starting task [Stage-0:DDL] in serial mode\n",
      "INFO  : Completed executing command(queryId=root_20240129124713_86eb1b6c-592d-4b01-b6ae-668c98fafcc2); Time taken: 0.017 seconds\n",
      "INFO  : OK\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "No rows affected (0.064 seconds)\n",
      "INFO  : Compiling command(queryId=root_20240129124713_5a2dd277-6f70-4277-80e3-2d923168c136): CREATE EXTERNAL TABLE IF NOT EXISTS flights (dayofmonth TINYINT, dayofweek TINYINT, carrier STRING,      depairportid STRING, arrairportid STRING, depdelay SMALLINT, arrdelay SMALLINT)  COMMENT 'Flights'  ROW FORMAT DELIMITED FIELDS TERMINATED BY '\\,'  TBLPROPERTIES ('Autor' = 'Jacobo Rodr?guez', 'Fecha' = '29/01/2024', 'skip.header.line.count'='1')\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Semantic Analysis Completed (retrial = false)\n",
      "INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)\n",
      "INFO  : Completed compiling command(queryId=root_20240129124713_5a2dd277-6f70-4277-80e3-2d923168c136); Time taken: 0.019 seconds\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Executing command(queryId=root_20240129124713_5a2dd277-6f70-4277-80e3-2d923168c136): CREATE EXTERNAL TABLE IF NOT EXISTS flights (dayofmonth TINYINT, dayofweek TINYINT, carrier STRING,      depairportid STRING, arrairportid STRING, depdelay SMALLINT, arrdelay SMALLINT)  COMMENT 'Flights'  ROW FORMAT DELIMITED FIELDS TERMINATED BY '\\,'  TBLPROPERTIES ('Autor' = 'Jacobo Rodr?guez', 'Fecha' = '29/01/2024', 'skip.header.line.count'='1')\n",
      "INFO  : Starting task [Stage-0:DDL] in serial mode\n",
      "INFO  : Completed executing command(queryId=root_20240129124713_5a2dd277-6f70-4277-80e3-2d923168c136); Time taken: 0.049 seconds\n",
      "INFO  : OK\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "No rows affected (0.078 seconds)\n",
      "Beeline version 3.1.2 by Apache Hive\n",
      "Closing: 0: jdbc:hive2://localhost:10000/bda03\n"
     ]
    }
   ],
   "source": [
    "! beeline -u \"jdbc:hive2://localhost:10000/bda03\" -e \" \\\n",
    "DROP TABLE IF EXISTS flights; \\\n",
    "CREATE EXTERNAL TABLE IF NOT EXISTS flights (dayofmonth TINYINT, dayofweek TINYINT, carrier STRING, \\\n",
    "    depairportid STRING, arrairportid STRING, depdelay SMALLINT, arrdelay SMALLINT) \\\n",
    "COMMENT 'Flights' \\\n",
    "ROW FORMAT DELIMITED FIELDS TERMINATED BY '\\,' \\\n",
    "TBLPROPERTIES ('Autor' = 'Jacobo Rodríguez', 'Fecha' = '29/01/2024', 'skip.header.line.count'='1');\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to jdbc:hive2://localhost:10000/bda03\n",
      "Connected to: Apache Hive (version 3.1.2)\n",
      "Driver: Hive JDBC (version 3.1.2)\n",
      "Transaction isolation: TRANSACTION_REPEATABLE_READ\n",
      "INFO  : Compiling command(queryId=root_20240129124735_442ff850-d3b9-4579-9e99-ee42f6f798bf): SELECT * FROM flights\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Semantic Analysis Completed (retrial = false)\n",
      "INFO  : Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:flights.dayofmonth, type:tinyint, comment:null), FieldSchema(name:flights.dayofweek, type:tinyint, comment:null), FieldSchema(name:flights.carrier, type:string, comment:null), FieldSchema(name:flights.depairportid, type:string, comment:null), FieldSchema(name:flights.arrairportid, type:string, comment:null), FieldSchema(name:flights.depdelay, type:smallint, comment:null), FieldSchema(name:flights.arrdelay, type:smallint, comment:null)], properties:null)\n",
      "INFO  : Completed compiling command(queryId=root_20240129124735_442ff850-d3b9-4579-9e99-ee42f6f798bf); Time taken: 0.114 seconds\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Executing command(queryId=root_20240129124735_442ff850-d3b9-4579-9e99-ee42f6f798bf): SELECT * FROM flights\n",
      "INFO  : Completed executing command(queryId=root_20240129124735_442ff850-d3b9-4579-9e99-ee42f6f798bf); Time taken: 0.0 seconds\n",
      "INFO  : OK\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "+---------------------+--------------------+------------------+-----------------------+-----------------------+-------------------+-------------------+\n",
      "| flights.dayofmonth  | flights.dayofweek  | flights.carrier  | flights.depairportid  | flights.arrairportid  | flights.depdelay  | flights.arrdelay  |\n",
      "+---------------------+--------------------+------------------+-----------------------+-----------------------+-------------------+-------------------+\n",
      "+---------------------+--------------------+------------------+-----------------------+-----------------------+-------------------+-------------------+\n",
      "No rows selected (0.193 seconds)\n",
      "Beeline version 3.1.2 by Apache Hive\n",
      "Closing: 0: jdbc:hive2://localhost:10000/bda03\n"
     ]
    }
   ],
   "source": [
    "! beeline -u \"jdbc:hive2://localhost:10000/bda03\" -e \"\\\n",
    "SELECT * FROM flights;\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "! hdfs dfs -chmod 777 /user/root/flights/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to jdbc:hive2://localhost:10000/bda03\n",
      "Connected to: Apache Hive (version 3.1.2)\n",
      "Driver: Hive JDBC (version 3.1.2)\n",
      "Transaction isolation: TRANSACTION_REPEATABLE_READ\n",
      "INFO  : Compiling command(queryId=root_20240129125113_8123de60-3004-400d-9274-d8fe53fca79c): LOAD DATA INPATH '/user/root/flights/airports.csv' OVERWRITE INTO TABLE airports\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Semantic Analysis Completed (retrial = false)\n",
      "INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)\n",
      "INFO  : Completed compiling command(queryId=root_20240129125113_8123de60-3004-400d-9274-d8fe53fca79c); Time taken: 0.048 seconds\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Executing command(queryId=root_20240129125113_8123de60-3004-400d-9274-d8fe53fca79c): LOAD DATA INPATH '/user/root/flights/airports.csv' OVERWRITE INTO TABLE airports\n",
      "INFO  : Starting task [Stage-0:MOVE] in serial mode\n",
      "INFO  : Loading data to table bda03.airports from hdfs://namenode:8020/user/root/flights/airports.csv\n",
      "INFO  : Starting task [Stage-1:STATS] in serial mode\n",
      "INFO  : Completed executing command(queryId=root_20240129125113_8123de60-3004-400d-9274-d8fe53fca79c); Time taken: 0.711 seconds\n",
      "INFO  : OK\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "No rows affected (0.788 seconds)\n",
      "Beeline version 3.1.2 by Apache Hive\n",
      "Closing: 0: jdbc:hive2://localhost:10000/bda03\n"
     ]
    }
   ],
   "source": [
    "! beeline -u \"jdbc:hive2://localhost:10000/bda03\" -e \" \\\n",
    "LOAD DATA INPATH '/user/root/flights/airports.csv' OVERWRITE INTO TABLE airports;\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to jdbc:hive2://localhost:10000/bda03\n",
      "Connected to: Apache Hive (version 3.1.2)\n",
      "Driver: Hive JDBC (version 3.1.2)\n",
      "Transaction isolation: TRANSACTION_REPEATABLE_READ\n",
      "INFO  : Compiling command(queryId=root_20240129125156_6f0dac45-7944-4ccd-8d8c-bfef41a90779): LOAD DATA INPATH '/user/root/flights/flights.csv' OVERWRITE INTO TABLE flights\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Semantic Analysis Completed (retrial = false)\n",
      "INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)\n",
      "INFO  : Completed compiling command(queryId=root_20240129125156_6f0dac45-7944-4ccd-8d8c-bfef41a90779); Time taken: 0.031 seconds\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Executing command(queryId=root_20240129125156_6f0dac45-7944-4ccd-8d8c-bfef41a90779): LOAD DATA INPATH '/user/root/flights/flights.csv' OVERWRITE INTO TABLE flights\n",
      "INFO  : Starting task [Stage-0:MOVE] in serial mode\n",
      "INFO  : Loading data to table bda03.flights from hdfs://namenode:8020/user/root/flights/flights.csv\n",
      "INFO  : Starting task [Stage-1:STATS] in serial mode\n",
      "INFO  : Completed executing command(queryId=root_20240129125156_6f0dac45-7944-4ccd-8d8c-bfef41a90779); Time taken: 0.353 seconds\n",
      "INFO  : OK\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "No rows affected (0.427 seconds)\n",
      "Beeline version 3.1.2 by Apache Hive\n",
      "Closing: 0: jdbc:hive2://localhost:10000/bda03\n"
     ]
    }
   ],
   "source": [
    "! beeline -u \"jdbc:hive2://localhost:10000/bda03\" -e \" \\\n",
    "LOAD DATA INPATH '/user/root/flights/flights.csv' OVERWRITE INTO TABLE flights;\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to jdbc:hive2://localhost:10000/bda03\n",
      "Connected to: Apache Hive (version 3.1.2)\n",
      "Driver: Hive JDBC (version 3.1.2)\n",
      "Transaction isolation: TRANSACTION_REPEATABLE_READ\n",
      "INFO  : Compiling command(queryId=root_20240129125236_e8e2c449-4f43-4b79-ac50-881a5ea55fd6): SELECT * FROM airports LIMIT 10\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Semantic Analysis Completed (retrial = false)\n",
      "INFO  : Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:airports.airportid, type:string, comment:null), FieldSchema(name:airports.city, type:string, comment:null), FieldSchema(name:airports.state, type:string, comment:null), FieldSchema(name:airports.airportname, type:string, comment:null)], properties:null)\n",
      "INFO  : Completed compiling command(queryId=root_20240129125236_e8e2c449-4f43-4b79-ac50-881a5ea55fd6); Time taken: 0.13 seconds\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Executing command(queryId=root_20240129125236_e8e2c449-4f43-4b79-ac50-881a5ea55fd6): SELECT * FROM airports LIMIT 10\n",
      "INFO  : Completed executing command(queryId=root_20240129125236_e8e2c449-4f43-4b79-ac50-881a5ea55fd6); Time taken: 0.0 seconds\n",
      "INFO  : OK\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "+---------------------+----------------+-----------------+--------------------------------------+\n",
      "| airports.airportid  | airports.city  | airports.state  |         airports.airportname         |\n",
      "+---------------------+----------------+-----------------+--------------------------------------+\n",
      "| 10165               | Adak Island    | AK              | Adak                                 |\n",
      "| 10299               | Anchorage      | AK              | Ted Stevens Anchorage International  |\n",
      "| 10304               | Aniak          | AK              | Aniak Airport                        |\n",
      "| 10754               | Barrow         | AK              | Wiley Post/Will Rogers Memorial      |\n",
      "| 10551               | Bethel         | AK              | Bethel Airport                       |\n",
      "| 10926               | Cordova        | AK              | Merle K Mudhole Smith                |\n",
      "| 14709               | Deadhorse      | AK              | Deadhorse Airport                    |\n",
      "| 11336               | Dillingham     | AK              | Dillingham Airport                   |\n",
      "| 11630               | Fairbanks      | AK              | Fairbanks International              |\n",
      "| 11997               | Gustavus       | AK              | Gustavus Airport                     |\n",
      "+---------------------+----------------+-----------------+--------------------------------------+\n",
      "10 rows selected (0.355 seconds)\n",
      "Beeline version 3.1.2 by Apache Hive\n",
      "Closing: 0: jdbc:hive2://localhost:10000/bda03\n"
     ]
    }
   ],
   "source": [
    "! beeline -u \"jdbc:hive2://localhost:10000/bda03\" -e \" \\\n",
    "SELECT * FROM airports LIMIT 10\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to jdbc:hive2://localhost:10000/bda03\n",
      "Connected to: Apache Hive (version 3.1.2)\n",
      "Driver: Hive JDBC (version 3.1.2)\n",
      "Transaction isolation: TRANSACTION_REPEATABLE_READ\n",
      "INFO  : Compiling command(queryId=root_20240129125505_1271ded6-3936-4531-be34-ea2b588dafc9): SELECT * FROM flights LIMIT 10\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Semantic Analysis Completed (retrial = false)\n",
      "INFO  : Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:flights.dayofmonth, type:tinyint, comment:null), FieldSchema(name:flights.dayofweek, type:tinyint, comment:null), FieldSchema(name:flights.carrier, type:string, comment:null), FieldSchema(name:flights.depairportid, type:string, comment:null), FieldSchema(name:flights.arrairportid, type:string, comment:null), FieldSchema(name:flights.depdelay, type:smallint, comment:null), FieldSchema(name:flights.arrdelay, type:smallint, comment:null)], properties:null)\n",
      "INFO  : Completed compiling command(queryId=root_20240129125505_1271ded6-3936-4531-be34-ea2b588dafc9); Time taken: 0.098 seconds\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Executing command(queryId=root_20240129125505_1271ded6-3936-4531-be34-ea2b588dafc9): SELECT * FROM flights LIMIT 10\n",
      "INFO  : Completed executing command(queryId=root_20240129125505_1271ded6-3936-4531-be34-ea2b588dafc9); Time taken: 0.0 seconds\n",
      "INFO  : OK\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "+---------------------+--------------------+------------------+-----------------------+-----------------------+-------------------+-------------------+\n",
      "| flights.dayofmonth  | flights.dayofweek  | flights.carrier  | flights.depairportid  | flights.arrairportid  | flights.depdelay  | flights.arrdelay  |\n",
      "+---------------------+--------------------+------------------+-----------------------+-----------------------+-------------------+-------------------+\n",
      "| 19                  | 5                  | DL               | 11433                 | 13303                 | -3                | 1                 |\n",
      "| 19                  | 5                  | DL               | 14869                 | 12478                 | 0                 | -8                |\n",
      "| 19                  | 5                  | DL               | 14057                 | 14869                 | -4                | -15               |\n",
      "| 19                  | 5                  | DL               | 15016                 | 11433                 | 28                | 24                |\n",
      "| 19                  | 5                  | DL               | 11193                 | 12892                 | -6                | -11               |\n",
      "| 19                  | 5                  | DL               | 10397                 | 15016                 | -1                | -19               |\n",
      "| 19                  | 5                  | DL               | 15016                 | 10397                 | 0                 | -1                |\n",
      "| 19                  | 5                  | DL               | 10397                 | 14869                 | 15                | 24                |\n",
      "| 19                  | 5                  | DL               | 10397                 | 10423                 | 33                | 34                |\n",
      "| 19                  | 5                  | DL               | 11278                 | 10397                 | 323               | 322               |\n",
      "+---------------------+--------------------+------------------+-----------------------+-----------------------+-------------------+-------------------+\n",
      "10 rows selected (0.418 seconds)\n",
      "Beeline version 3.1.2 by Apache Hive\n",
      "Closing: 0: jdbc:hive2://localhost:10000/bda03\n"
     ]
    }
   ],
   "source": [
    "! beeline -u \"jdbc:hive2://localhost:10000/bda03\" -e \" \\\n",
    "SELECT * FROM flights LIMIT 10\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing flights.pig\n"
     ]
    }
   ],
   "source": [
    "%%writefile flights.pig\n",
    "\n",
    "-- registro de la librería PiggyBank\n",
    "REGISTER piggybank.jar\n",
    "\n",
    "-- Lectura CSV\n",
    "\n",
    "AIRPORTS = LOAD '$airports_file' USING\n",
    "    org.apache.pig.piggybank.storage.CSVExcelStorage(',','NO_MULTILINE','UNIX','SKIP_INPUT_HEADER')\n",
    "    AS (airportid:chararray, city:chararray, state:chararray, airportname:chararray);\n",
    "\n",
    "FLIGHTS = LOAD '$flights_file' USING\n",
    "    org.apache.pig.piggybank.storage.CSVExcelStorage(',','NO_MULTILINE','UNIX','SKIP_INPUT_HEADER')\n",
    "    AS (dayofmonth:int, dayofweek:int, carrier:chararray,\n",
    "           depairport:chararray, arrairportid:chararray, depdelay:int, arrdelay:int);\n",
    "\n",
    "-- Nos quedamos con 10 aeropuertos\n",
    "AIRPORTS_10 = LIMIT AIRPORTS 10;\n",
    "\n",
    "-- Muestra de 10 aeropuertos\n",
    "DUMP AIRPORTS_10;\n",
    "\n",
    "-- Mismo procedimiento con los vuelos\n",
    "FLIGHTS_10 = LIMIT FLIGHTS 10;\n",
    "DUMP FLIGHTS_10;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-29 14:31:22,518 INFO pig.ExecTypeProvider: Trying ExecType : LOCAL\n",
      "2024-01-29 14:31:22,519 INFO pig.ExecTypeProvider: Picked LOCAL as the ExecType\n",
      "2024-01-29 14:31:22,560 [main] INFO  org.apache.pig.Main - Apache Pig version 0.17.0 (r1797386) compiled Jun 02 2017, 15:41:58\n",
      "2024-01-29 14:31:22,560 [main] INFO  org.apache.pig.Main - Logging error messages to: /media/notebooks/pig_1706535082558.log\n",
      "2024-01-29 14:31:22,573 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - user.name is deprecated. Instead, use mapreduce.job.user.name\n",
      "2024-01-29 14:31:22,681 [main] INFO  org.apache.pig.impl.util.Utils - Default bootup file /root/.pigbootup not found\n",
      "2024-01-29 14:31:22,725 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address\n",
      "2024-01-29 14:31:22,726 [main] INFO  org.apache.pig.backend.hadoop.executionengine.HExecutionEngine - Connecting to hadoop file system at: file:///\n",
      "2024-01-29 14:31:22,745 [main] INFO  org.apache.pig.PigServer - Pig Script ID for the session: PIG-flights.pig-daab0664-2828-4ec0-8efd-632bdb44aff6\n",
      "2024-01-29 14:31:22,745 [main] WARN  org.apache.pig.PigServer - ATS is disabled since yarn.timeline-service.enabled set to false\n",
      "2024-01-29 14:31:23,288 [main] INFO  org.apache.pig.tools.pigstats.ScriptState - Pig features used in the script: LIMIT\n",
      "2024-01-29 14:31:23,324 [main] INFO  org.apache.pig.newplan.logical.optimizer.LogicalPlanOptimizer - {RULES_ENABLED=[AddForEach, ColumnMapKeyPrune, ConstantCalculator, GroupByConstParallelSetter, LimitOptimizer, LoadTypeCastInserter, MergeFilter, MergeForEach, NestedLimitOptimizer, PartitionFilterOptimizer, PredicatePushdownOptimizer, PushDownForEachFlatten, PushUpFilter, SplitFilter, StreamTypeCastInserter]}\n",
      "2024-01-29 14:31:23,379 [main] INFO  org.apache.pig.impl.util.SpillableMemoryManager - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128\n",
      "2024-01-29 14:31:23,417 [main] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-01-29 14:31:23,417 [main] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-01-29 14:31:23,461 [main] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\n",
      "2024-01-29 14:31:23,470 [main] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2024-01-29 14:31:23,472 [main] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths to process : 1\n",
      "2024-01-29 14:31:23,507 [main] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt__0001_m_000001_1' to file:/tmp/temp1101812674/tmp-1741092329\n",
      "2024-01-29 14:31:23,511 [main] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\n",
      "2024-01-29 14:31:23,515 [main] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2024-01-29 14:31:23,515 [main] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths to process : 1\n",
      "(10165,Adak Island,AK,Adak)\n",
      "(10299,Anchorage,AK,Ted Stevens Anchorage International)\n",
      "(10304,Aniak,AK,Aniak Airport)\n",
      "(10754,Barrow,AK,Wiley Post/Will Rogers Memorial)\n",
      "(10551,Bethel,AK,Bethel Airport)\n",
      "(10926,Cordova,AK,Merle K Mudhole Smith)\n",
      "(14709,Deadhorse,AK,Deadhorse Airport)\n",
      "(11336,Dillingham,AK,Dillingham Airport)\n",
      "(11630,Fairbanks,AK,Fairbanks International)\n",
      "(11997,Gustavus,AK,Gustavus Airport)\n",
      "2024-01-29 14:31:23,599 [main] INFO  org.apache.pig.tools.pigstats.ScriptState - Pig features used in the script: LIMIT\n",
      "2024-01-29 14:31:23,608 [main] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\n",
      "2024-01-29 14:31:23,609 [main] INFO  org.apache.pig.newplan.logical.optimizer.LogicalPlanOptimizer - {RULES_ENABLED=[AddForEach, ColumnMapKeyPrune, ConstantCalculator, GroupByConstParallelSetter, LimitOptimizer, LoadTypeCastInserter, MergeFilter, MergeForEach, NestedLimitOptimizer, PartitionFilterOptimizer, PredicatePushdownOptimizer, PushDownForEachFlatten, PushUpFilter, SplitFilter, StreamTypeCastInserter]}\n",
      "2024-01-29 14:31:23,621 [main] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-01-29 14:31:23,621 [main] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-01-29 14:31:23,634 [main] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\n",
      "2024-01-29 14:31:23,640 [main] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2024-01-29 14:31:23,640 [main] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths to process : 1\n",
      "2024-01-29 14:31:23,653 [main] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt__0001_m_000001_1' to file:/tmp/temp1101812674/tmp370643906\n",
      "2024-01-29 14:31:23,655 [main] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\n",
      "2024-01-29 14:31:23,656 [main] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2024-01-29 14:31:23,656 [main] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths to process : 1\n",
      "(19,5,DL,11433,13303,-3,1)\n",
      "(19,5,DL,14869,12478,0,-8)\n",
      "(19,5,DL,14057,14869,-4,-15)\n",
      "(19,5,DL,15016,11433,28,24)\n",
      "(19,5,DL,11193,12892,-6,-11)\n",
      "(19,5,DL,10397,15016,-1,-19)\n",
      "(19,5,DL,15016,10397,0,-1)\n",
      "(19,5,DL,10397,14869,15,24)\n",
      "(19,5,DL,10397,10423,33,34)\n",
      "(19,5,DL,11278,10397,323,322)\n",
      "2024-01-29 14:31:23,693 [main] INFO  org.apache.pig.Main - Pig script completed in 1 second and 290 milliseconds (1290 ms)\n"
     ]
    }
   ],
   "source": [
    "! pig -x local -f flights.pig -param airports_file='airports.csv' -param flights_file='flights.csv' -param output_dir='pig/output/flights'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.- Con una consulta de HQL muestra: La cinco compañías que más vuelos retrasados tienen.\n",
    "\n",
    "* El campo `carrier` contiene la compañía aérea.\n",
    "* Vamos a considerar que un vuelo llega con retraso cuando el vuelo llega más de 15 minutos tarde (campo `arrdelay` > 15).\n",
    "\n",
    "Se espera el siguiente resultado:\n",
    "\n",
    "![solución 2](./img/2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to jdbc:hive2://localhost:10000/bda03\n",
      "Connected to: Apache Hive (version 3.1.2)\n",
      "Driver: Hive JDBC (version 3.1.2)\n",
      "Transaction isolation: TRANSACTION_REPEATABLE_READ\n",
      "INFO  : Compiling command(queryId=root_20240129133354_4a068ccf-1382-4807-9a5d-1c7684a7bcdd): SELECT f.carrier, COUNT(*) as delayed_flights  FROM flights f  WHERE f.arrdelay > 15  GROUP BY f.carrier  ORDER BY delayed_flights DESC  LIMIT 5\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Semantic Analysis Completed (retrial = false)\n",
      "INFO  : Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:f.carrier, type:string, comment:null), FieldSchema(name:delayed_flights, type:bigint, comment:null)], properties:null)\n",
      "INFO  : Completed compiling command(queryId=root_20240129133354_4a068ccf-1382-4807-9a5d-1c7684a7bcdd); Time taken: 0.137 seconds\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Executing command(queryId=root_20240129133354_4a068ccf-1382-4807-9a5d-1c7684a7bcdd): SELECT f.carrier, COUNT(*) as delayed_flights  FROM flights f  WHERE f.arrdelay > 15  GROUP BY f.carrier  ORDER BY delayed_flights DESC  LIMIT 5\n",
      "WARN  : Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.\n",
      "INFO  : Query ID = root_20240129133354_4a068ccf-1382-4807-9a5d-1c7684a7bcdd\n",
      "INFO  : Total jobs = 2\n",
      "INFO  : Launching Job 1 out of 2\n",
      "INFO  : Starting task [Stage-1:MAPRED] in serial mode\n",
      "INFO  : Number of reduce tasks not specified. Estimated from input data size: 1\n",
      "INFO  : In order to change the average load for a reducer (in bytes):\n",
      "INFO  :   set hive.exec.reducers.bytes.per.reducer=<number>\n",
      "INFO  : In order to limit the maximum number of reducers:\n",
      "INFO  :   set hive.exec.reducers.max=<number>\n",
      "INFO  : In order to set a constant number of reducers:\n",
      "INFO  :   set mapreduce.job.reduces=<number>\n",
      "INFO  : number of splits:1\n",
      "INFO  : Submitting tokens for job: job_1706525461108_0007\n",
      "INFO  : Executing with tokens: []\n",
      "INFO  : The url to track the job: http://yarnmaster:8088/proxy/application_1706525461108_0007/\n",
      "INFO  : Starting Job = job_1706525461108_0007, Tracking URL = http://yarnmaster:8088/proxy/application_1706525461108_0007/\n",
      "INFO  : Kill Command = /app/hadoop-3.3.1/bin/mapred job  -kill job_1706525461108_0007\n",
      "INFO  : Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1\n",
      "INFO  : 2024-01-29 13:33:59,320 Stage-1 map = 0%,  reduce = 0%\n",
      "INFO  : 2024-01-29 13:34:05,447 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 3.63 sec\n",
      "INFO  : 2024-01-29 13:34:10,548 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 5.55 sec\n",
      "INFO  : MapReduce Total cumulative CPU time: 5 seconds 550 msec\n",
      "INFO  : Ended Job = job_1706525461108_0007\n",
      "INFO  : Launching Job 2 out of 2\n",
      "INFO  : Starting task [Stage-2:MAPRED] in serial mode\n",
      "INFO  : Number of reduce tasks determined at compile time: 1\n",
      "INFO  : In order to change the average load for a reducer (in bytes):\n",
      "INFO  :   set hive.exec.reducers.bytes.per.reducer=<number>\n",
      "INFO  : In order to limit the maximum number of reducers:\n",
      "INFO  :   set hive.exec.reducers.max=<number>\n",
      "INFO  : In order to set a constant number of reducers:\n",
      "INFO  :   set mapreduce.job.reduces=<number>\n",
      "INFO  : number of splits:1\n",
      "INFO  : Submitting tokens for job: job_1706525461108_0008\n",
      "INFO  : Executing with tokens: []\n",
      "INFO  : The url to track the job: http://yarnmaster:8088/proxy/application_1706525461108_0008/\n",
      "INFO  : Starting Job = job_1706525461108_0008, Tracking URL = http://yarnmaster:8088/proxy/application_1706525461108_0008/\n",
      "INFO  : Kill Command = /app/hadoop-3.3.1/bin/mapred job  -kill job_1706525461108_0008\n",
      "INFO  : Hadoop job information for Stage-2: number of mappers: 1; number of reducers: 1\n",
      "INFO  : 2024-01-29 13:34:16,994 Stage-2 map = 0%,  reduce = 0%\n",
      "INFO  : 2024-01-29 13:34:22,090 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 1.08 sec\n",
      "INFO  : 2024-01-29 13:34:26,160 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 2.7 sec\n",
      "INFO  : MapReduce Total cumulative CPU time: 2 seconds 700 msec\n",
      "INFO  : Ended Job = job_1706525461108_0008\n",
      "INFO  : MapReduce Jobs Launched: \n",
      "INFO  : Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 5.55 sec   HDFS Read: 72103090 HDFS Write: 465 SUCCESS\n",
      "INFO  : Stage-Stage-2: Map: 1  Reduce: 1   Cumulative CPU: 2.7 sec   HDFS Read: 8071 HDFS Write: 193 SUCCESS\n",
      "INFO  : Total MapReduce CPU Time Spent: 8 seconds 250 msec\n",
      "INFO  : Completed executing command(queryId=root_20240129133354_4a068ccf-1382-4807-9a5d-1c7684a7bcdd); Time taken: 32.339 seconds\n",
      "INFO  : OK\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "+------------+------------------+\n",
      "| f.carrier  | delayed_flights  |\n",
      "+------------+------------------+\n",
      "| WN         | 127601           |\n",
      "| AA         | 59842            |\n",
      "| DL         | 57668            |\n",
      "| UA         | 57367            |\n",
      "| US         | 40943            |\n",
      "+------------+------------------+\n",
      "5 rows selected (32.521 seconds)\n",
      "Beeline version 3.1.2 by Apache Hive\n",
      "Closing: 0: jdbc:hive2://localhost:10000/bda03\n"
     ]
    }
   ],
   "source": [
    "! beeline -u \"jdbc:hive2://localhost:10000/bda03\" -e \" \\\n",
    "SELECT f.carrier, COUNT(*) as delayed_flights \\\n",
    "FROM flights f \\\n",
    "WHERE f.arrdelay > 15 \\\n",
    "GROUP BY f.carrier \\\n",
    "ORDER BY delayed_flights DESC \\\n",
    "LIMIT 5;\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.- Con una consulta de HQL muestra: Las 5 compañías que mejor recuperación de tiempo en vuelo tienen.\n",
    "\n",
    "* Se considera que se ha recuperado el tiempo de un vuelo cuando habiendo salido con retraso (`depdelay` > 15), llega sin retraso (`arraydelay` <= 15).\n",
    "* Se trata de que muestres las 5 compañías que han recuperado el tiempo en un mayor porcentaje de vuelos que salieron retrasados.\n",
    "\n",
    "El resultado esperado es el siguiente:\n",
    "\n",
    "![solución 3](./img/3.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to jdbc:hive2://localhost:10000/bda03\n",
      "Connected to: Apache Hive (version 3.1.2)\n",
      "Driver: Hive JDBC (version 3.1.2)\n",
      "Transaction isolation: TRANSACTION_REPEATABLE_READ\n",
      "INFO  : Compiling command(queryId=root_20240129134211_137e6b7e-e80a-4e38-b667-efb4532fea02): SELECT f.carrier,         SUM(CASE WHEN f.depdelay > 15 AND f.arrdelay <= 15 THEN 1 ELSE 0 END) * 1.0 / COUNT(*) AS percent_recovered  FROM flights f  WHERE f.depdelay > 15  GROUP BY carrier  ORDER BY percent_recovered DESC  LIMIT 5\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Semantic Analysis Completed (retrial = false)\n",
      "INFO  : Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:f.carrier, type:string, comment:null), FieldSchema(name:percent_recovered, type:decimal(38,17), comment:null)], properties:null)\n",
      "INFO  : Completed compiling command(queryId=root_20240129134211_137e6b7e-e80a-4e38-b667-efb4532fea02); Time taken: 0.124 seconds\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Executing command(queryId=root_20240129134211_137e6b7e-e80a-4e38-b667-efb4532fea02): SELECT f.carrier,         SUM(CASE WHEN f.depdelay > 15 AND f.arrdelay <= 15 THEN 1 ELSE 0 END) * 1.0 / COUNT(*) AS percent_recovered  FROM flights f  WHERE f.depdelay > 15  GROUP BY carrier  ORDER BY percent_recovered DESC  LIMIT 5\n",
      "WARN  : Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.\n",
      "INFO  : Query ID = root_20240129134211_137e6b7e-e80a-4e38-b667-efb4532fea02\n",
      "INFO  : Total jobs = 2\n",
      "INFO  : Launching Job 1 out of 2\n",
      "INFO  : Starting task [Stage-1:MAPRED] in serial mode\n",
      "INFO  : Number of reduce tasks not specified. Estimated from input data size: 1\n",
      "INFO  : In order to change the average load for a reducer (in bytes):\n",
      "INFO  :   set hive.exec.reducers.bytes.per.reducer=<number>\n",
      "INFO  : In order to limit the maximum number of reducers:\n",
      "INFO  :   set hive.exec.reducers.max=<number>\n",
      "INFO  : In order to set a constant number of reducers:\n",
      "INFO  :   set mapreduce.job.reduces=<number>\n",
      "INFO  : number of splits:1\n",
      "INFO  : Submitting tokens for job: job_1706525461108_0013\n",
      "INFO  : Executing with tokens: []\n",
      "INFO  : The url to track the job: http://yarnmaster:8088/proxy/application_1706525461108_0013/\n",
      "INFO  : Starting Job = job_1706525461108_0013, Tracking URL = http://yarnmaster:8088/proxy/application_1706525461108_0013/\n",
      "INFO  : Kill Command = /app/hadoop-3.3.1/bin/mapred job  -kill job_1706525461108_0013\n",
      "INFO  : Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1\n",
      "INFO  : 2024-01-29 13:42:15,818 Stage-1 map = 0%,  reduce = 0%\n",
      "INFO  : 2024-01-29 13:42:21,935 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 3.29 sec\n",
      "INFO  : 2024-01-29 13:42:28,045 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 5.56 sec\n",
      "INFO  : MapReduce Total cumulative CPU time: 5 seconds 560 msec\n",
      "INFO  : Ended Job = job_1706525461108_0013\n",
      "INFO  : Launching Job 2 out of 2\n",
      "INFO  : Starting task [Stage-2:MAPRED] in serial mode\n",
      "INFO  : Number of reduce tasks determined at compile time: 1\n",
      "INFO  : In order to change the average load for a reducer (in bytes):\n",
      "INFO  :   set hive.exec.reducers.bytes.per.reducer=<number>\n",
      "INFO  : In order to limit the maximum number of reducers:\n",
      "INFO  :   set hive.exec.reducers.max=<number>\n",
      "INFO  : In order to set a constant number of reducers:\n",
      "INFO  :   set mapreduce.job.reduces=<number>\n",
      "INFO  : number of splits:1\n",
      "INFO  : Submitting tokens for job: job_1706525461108_0014\n",
      "INFO  : Executing with tokens: []\n",
      "INFO  : The url to track the job: http://yarnmaster:8088/proxy/application_1706525461108_0014/\n",
      "INFO  : Starting Job = job_1706525461108_0014, Tracking URL = http://yarnmaster:8088/proxy/application_1706525461108_0014/\n",
      "INFO  : Kill Command = /app/hadoop-3.3.1/bin/mapred job  -kill job_1706525461108_0014\n",
      "INFO  : Hadoop job information for Stage-2: number of mappers: 1; number of reducers: 1\n",
      "INFO  : 2024-01-29 13:42:34,503 Stage-2 map = 0%,  reduce = 0%\n",
      "INFO  : 2024-01-29 13:42:37,561 Stage-2 map = 100%,  reduce = 0%\n",
      "INFO  : 2024-01-29 13:42:42,642 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 2.7 sec\n",
      "INFO  : MapReduce Total cumulative CPU time: 2 seconds 700 msec\n",
      "INFO  : Ended Job = job_1706525461108_0014\n",
      "INFO  : MapReduce Jobs Launched: \n",
      "INFO  : Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 5.56 sec   HDFS Read: 72106091 HDFS Write: 560 SUCCESS\n",
      "INFO  : Stage-Stage-2: Map: 1  Reduce: 1   Cumulative CPU: 2.7 sec   HDFS Read: 8239 HDFS Write: 262 SUCCESS\n",
      "INFO  : Total MapReduce CPU Time Spent: 8 seconds 260 msec\n",
      "INFO  : Completed executing command(queryId=root_20240129134211_137e6b7e-e80a-4e38-b667-efb4532fea02); Time taken: 33.247 seconds\n",
      "INFO  : OK\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "+------------+----------------------+\n",
      "| f.carrier  |  percent_recovered   |\n",
      "+------------+----------------------+\n",
      "| UA         | 0.24507301133462677  |\n",
      "| WN         | 0.23570878543927196  |\n",
      "| FL         | 0.22657288435976961  |\n",
      "| DL         | 0.21578780710414067  |\n",
      "| AA         | 0.20162014676224855  |\n",
      "+------------+----------------------+\n",
      "5 rows selected (33.414 seconds)\n",
      "Beeline version 3.1.2 by Apache Hive\n",
      "Closing: 0: jdbc:hive2://localhost:10000/bda03\n"
     ]
    }
   ],
   "source": [
    "! beeline -u \"jdbc:hive2://localhost:10000/bda03\" -e \" \\\n",
    "SELECT f.carrier, \\\n",
    "       SUM(CASE WHEN f.depdelay > 15 AND f.arrdelay <= 15 THEN 1 ELSE 0 END) * 1.0 / COUNT(*) AS percent_recovered \\\n",
    "FROM flights f \\\n",
    "WHERE f.depdelay > 15 \\\n",
    "GROUP BY carrier \\\n",
    "ORDER BY percent_recovered DESC \\\n",
    "LIMIT 5;\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.- Resuelve el ejercicio 2 con Pig Latin\n",
    "\n",
    "El resultado esperado es:\n",
    "\n",
    "![solución 4](./img/4.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting delayed_flights.pig\n"
     ]
    }
   ],
   "source": [
    "%%writefile delayed_flights.pig\n",
    "\n",
    "-- registro de la librería PiggyBank\n",
    "REGISTER piggybank.jar\n",
    "\n",
    "-- Lectura CSV\n",
    "\n",
    "AIRPORTS = LOAD '$airports_file' USING\n",
    "    org.apache.pig.piggybank.storage.CSVExcelStorage(',','NO_MULTILINE','UNIX','SKIP_INPUT_HEADER')\n",
    "    AS (airportid:chararray, city:chararray, state:chararray, airportname:chararray);\n",
    "\n",
    "FLIGHTS = LOAD '$flights_file' USING\n",
    "    org.apache.pig.piggybank.storage.CSVExcelStorage(',','NO_MULTILINE','UNIX','SKIP_INPUT_HEADER')\n",
    "    AS (dayofmonth:int, dayofweek:int, carrier:chararray,\n",
    "           depairport:chararray, arrairportid:chararray, depdelay:int, arrdelay:int);\n",
    "\n",
    "-- Seleccionamos los vuelos retrasados\n",
    "vuelos_retrasados = FILTER FLIGHTS BY arrdelay > 15;\n",
    "\n",
    "-- Cuenta de los vuelos retrasados relacionandolos con la compañía\n",
    "contar_retrasos = GROUP vuelos_retrasados BY carrier;\n",
    "total_retrasos = FOREACH contar_retrasos GENERATE group AS carrier, COUNT(vuelos_retrasados) AS total_retrasos;\n",
    "\n",
    "-- Ordenar DESC y limitar a 5 las compañías\n",
    "top5_retrasos = ORDER total_retrasos BY total_retrasos DESC;\n",
    "top5_retrasos = LIMIT top5_retrasos 5;\n",
    "\n",
    "-- DUMP del resultado\n",
    "DUMP top5_retrasos;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-29 15:53:40,892 INFO pig.ExecTypeProvider: Trying ExecType : LOCAL\n",
      "2024-01-29 15:53:40,893 INFO pig.ExecTypeProvider: Picked LOCAL as the ExecType\n",
      "2024-01-29 15:53:40,928 [main] INFO  org.apache.pig.Main - Apache Pig version 0.17.0 (r1797386) compiled Jun 02 2017, 15:41:58\n",
      "2024-01-29 15:53:40,928 [main] INFO  org.apache.pig.Main - Logging error messages to: /media/notebooks/pig_1706540020927.log\n",
      "2024-01-29 15:53:40,938 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - user.name is deprecated. Instead, use mapreduce.job.user.name\n",
      "2024-01-29 15:53:41,029 [main] INFO  org.apache.pig.impl.util.Utils - Default bootup file /root/.pigbootup not found\n",
      "2024-01-29 15:53:41,071 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address\n",
      "2024-01-29 15:53:41,072 [main] INFO  org.apache.pig.backend.hadoop.executionengine.HExecutionEngine - Connecting to hadoop file system at: file:///\n",
      "2024-01-29 15:53:41,087 [main] INFO  org.apache.pig.PigServer - Pig Script ID for the session: PIG-delayed_flights.pig-4c6b06af-4f92-4324-8783-0be71147ef34\n",
      "2024-01-29 15:53:41,087 [main] WARN  org.apache.pig.PigServer - ATS is disabled since yarn.timeline-service.enabled set to false\n",
      "2024-01-29 15:53:41,618 [main] INFO  org.apache.pig.tools.pigstats.ScriptState - Pig features used in the script: GROUP_BY,ORDER_BY,FILTER,LIMIT\n",
      "2024-01-29 15:53:41,657 [main] INFO  org.apache.pig.newplan.logical.optimizer.LogicalPlanOptimizer - {RULES_ENABLED=[AddForEach, ColumnMapKeyPrune, ConstantCalculator, GroupByConstParallelSetter, LimitOptimizer, LoadTypeCastInserter, MergeFilter, MergeForEach, NestedLimitOptimizer, PartitionFilterOptimizer, PredicatePushdownOptimizer, PushDownForEachFlatten, PushUpFilter, SplitFilter, StreamTypeCastInserter]}\n",
      "2024-01-29 15:53:41,689 [main] INFO  org.apache.pig.impl.util.SpillableMemoryManager - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128\n",
      "2024-01-29 15:53:41,717 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler - File concatenation threshold: 100 optimistic? false\n",
      "2024-01-29 15:53:41,728 [main] INFO  org.apache.pig.backend.hadoop.executionengine.util.CombinerOptimizerUtil - Choosing to move algebraic foreach to combiner\n",
      "2024-01-29 15:53:41,741 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.SecondaryKeyOptimizerMR - Using Secondary Key Optimization for MapReduce node scope-43\n",
      "2024-01-29 15:53:41,746 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer - MR plan size before optimization: 4\n",
      "2024-01-29 15:53:41,746 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer - MR plan size after optimization: 4\n",
      "2024-01-29 15:53:41,828 [main] INFO  org.apache.hadoop.metrics2.impl.MetricsConfig - Loaded properties from hadoop-metrics2.properties\n",
      "2024-01-29 15:53:41,877 [main] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - Scheduled Metric snapshot period at 10 second(s).\n",
      "2024-01-29 15:53:41,877 [main] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system started\n",
      "2024-01-29 15:53:41,891 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState - Pig script settings are added to the job\n",
      "2024-01-29 15:53:41,894 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.reduce.markreset.buffer.percent is deprecated. Instead, use mapreduce.reduce.markreset.buffer.percent\n",
      "2024-01-29 15:53:41,894 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3\n",
      "2024-01-29 15:53:41,895 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.output.compress is deprecated. Instead, use mapreduce.output.fileoutputformat.compress\n",
      "2024-01-29 15:53:41,896 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Reduce phase detected, estimating # of required reducers.\n",
      "2024-01-29 15:53:41,897 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Using reducer estimator: org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.InputSizeReducerEstimator\n",
      "2024-01-29 15:53:41,903 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.InputSizeReducerEstimator - BytesPerReducer=1000000000 maxReducers=999 totalInputFileSize=72088113\n",
      "2024-01-29 15:53:41,903 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Setting Parallelism to 1\n",
      "2024-01-29 15:53:41,903 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces\n",
      "2024-01-29 15:53:41,911 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Setting up single store job\n",
      "2024-01-29 15:53:41,922 [main] INFO  org.apache.pig.data.SchemaTupleFrontend - Key [pig.schematuple] is false, will not generate code.\n",
      "2024-01-29 15:53:41,922 [main] INFO  org.apache.pig.data.SchemaTupleFrontend - Starting process to move generated code to distributed cacche\n",
      "2024-01-29 15:53:41,922 [main] INFO  org.apache.pig.data.SchemaTupleFrontend - Distributed cache not supported or needed in local mode. Setting key [pig.schematuple.local.dir] with code temp directory: /tmp/1706540021922-0\n",
      "2024-01-29 15:53:41,972 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 1 map-reduce job(s) waiting for submission.\n",
      "2024-01-29 15:53:41,978 [JobControl] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-01-29 15:53:41,985 [JobControl] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id\n",
      "2024-01-29 15:53:42,009 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
      "2024-01-29 15:53:42,023 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2024-01-29 15:53:42,023 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths to process : 1\n",
      "2024-01-29 15:53:42,032 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths (combined) to process : 3\n",
      "2024-01-29 15:53:42,051 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:3\n",
      "2024-01-29 15:53:42,124 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local833473054_0001\n",
      "2024-01-29 15:53:42,124 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Executing with tokens: []\n",
      "2024-01-29 15:53:42,203 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/\n",
      "2024-01-29 15:53:42,204 [Thread-6] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null\n",
      "2024-01-29 15:53:42,221 [Thread-6] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces\n",
      "2024-01-29 15:53:42,221 [Thread-6] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address\n",
      "2024-01-29 15:53:42,221 [Thread-6] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.reduce.markreset.buffer.percent is deprecated. Instead, use mapreduce.reduce.markreset.buffer.percent\n",
      "2024-01-29 15:53:42,224 [Thread-6] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-01-29 15:53:42,224 [Thread-6] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-01-29 15:53:42,224 [Thread-6] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigOutputCommitter\n",
      "2024-01-29 15:53:42,252 [Thread-6] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks\n",
      "2024-01-29 15:53:42,252 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local833473054_0001_m_000000_0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-29 15:53:42,276 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-01-29 15:53:42,276 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-01-29 15:53:42,287 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2024-01-29 15:53:42,291 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Processing split: Number of splits :1\n",
      "Total Length = 33554432\n",
      "Input split[0]:\n",
      "   Length = 33554432\n",
      "   ClassName: org.apache.hadoop.mapreduce.lib.input.FileSplit\n",
      "   Locations:\n",
      "\n",
      "-----------------------\n",
      "\n",
      "2024-01-29 15:53:42,299 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigRecordReader - Current split being processed file:/media/notebooks/flights.csv:0+33554432\n",
      "2024-01-29 15:53:42,321 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)\n",
      "2024-01-29 15:53:42,321 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100\n",
      "2024-01-29 15:53:42,321 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - soft limit at 83886080\n",
      "2024-01-29 15:53:42,321 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600\n",
      "2024-01-29 15:53:42,321 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600\n",
      "2024-01-29 15:53:42,325 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "2024-01-29 15:53:42,346 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.impl.util.SpillableMemoryManager - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128\n",
      "2024-01-29 15:53:42,348 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.data.SchemaTupleBackend - Key [pig.schematuple] was not set... will not generate code.\n",
      "2024-01-29 15:53:42,360 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigGenericMapReduce$Map - Aliases being processed per job phase (AliasName[line,offset]): M: FLIGHTS[11,10],FLIGHTS[-1,-1],vuelos_retrasados[17,20],total_retrasos[21,17],contar_retrasos[20,18] C: total_retrasos[21,17],contar_retrasos[20,18] R: total_retrasos[21,17]\n",
      "2024-01-29 15:53:42,483 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - HadoopJobId: job_local833473054_0001\n",
      "2024-01-29 15:53:42,483 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - Processing aliases FLIGHTS,contar_retrasos,total_retrasos,vuelos_retrasados\n",
      "2024-01-29 15:53:42,483 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - detailed locations: M: FLIGHTS[11,10],FLIGHTS[-1,-1],vuelos_retrasados[17,20],total_retrasos[21,17],contar_retrasos[20,18] C: total_retrasos[21,17],contar_retrasos[20,18] R: total_retrasos[21,17]\n",
      "2024-01-29 15:53:42,485 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 0% complete\n",
      "2024-01-29 15:53:42,485 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - Running jobs are [job_local833473054_0001]\n",
      "2024-01-29 15:53:46,261 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - \n",
      "2024-01-29 15:53:46,261 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Starting flush of map output\n",
      "2024-01-29 15:53:46,261 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Spilling map output\n",
      "2024-01-29 15:53:46,261 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 2747750; bufvoid = 104857600\n",
      "2024-01-29 15:53:46,261 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 25115300(100461200); length = 1099097/6553600\n",
      "2024-01-29 15:53:46,334 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigCombiner$Combine - Aliases being processed per job phase (AliasName[line,offset]): M: FLIGHTS[11,10],FLIGHTS[-1,-1],vuelos_retrasados[17,20],total_retrasos[21,17],contar_retrasos[20,18] C: total_retrasos[21,17],contar_retrasos[20,18] R: total_retrasos[21,17]\n",
      "2024-01-29 15:53:46,468 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Finished spill 0\n",
      "2024-01-29 15:53:46,477 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local833473054_0001_m_000000_0 is done. And is in the process of committing\n",
      "2024-01-29 15:53:46,478 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - map\n",
      "2024-01-29 15:53:46,478 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local833473054_0001_m_000000_0' done.\n",
      "2024-01-29 15:53:46,482 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local833473054_0001_m_000000_0: Counters: 18\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=33559711\n",
      "\t\tFILE: Number of bytes written=629317\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=1257485\n",
      "\t\tMap output records=274775\n",
      "\t\tMap output bytes=2747750\n",
      "\t\tMap output materialized bytes=234\n",
      "\t\tInput split bytes=360\n",
      "\t\tCombine input records=274775\n",
      "\t\tCombine output records=16\n",
      "\t\tSpilled Records=16\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=35\n",
      "\t\tTotal committed heap usage (bytes)=495452160\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=0\n",
      "2024-01-29 15:53:46,483 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local833473054_0001_m_000000_0\n",
      "2024-01-29 15:53:46,483 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local833473054_0001_m_000001_0\n",
      "2024-01-29 15:53:46,487 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 12% complete\n",
      "2024-01-29 15:53:46,487 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - Running jobs are [job_local833473054_0001]\n",
      "2024-01-29 15:53:46,487 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-01-29 15:53:46,488 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-01-29 15:53:46,488 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2024-01-29 15:53:46,489 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Processing split: Number of splits :1\n",
      "Total Length = 33554432\n",
      "Input split[0]:\n",
      "   Length = 33554432\n",
      "   ClassName: org.apache.hadoop.mapreduce.lib.input.FileSplit\n",
      "   Locations:\n",
      "\n",
      "-----------------------\n",
      "\n",
      "2024-01-29 15:53:46,492 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigRecordReader - Current split being processed file:/media/notebooks/flights.csv:33554432+33554432\n",
      "2024-01-29 15:53:46,498 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)\n",
      "2024-01-29 15:53:46,498 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100\n",
      "2024-01-29 15:53:46,499 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - soft limit at 83886080\n",
      "2024-01-29 15:53:46,499 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600\n",
      "2024-01-29 15:53:46,499 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600\n",
      "2024-01-29 15:53:46,500 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "2024-01-29 15:53:46,512 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.impl.util.SpillableMemoryManager - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128\n",
      "2024-01-29 15:53:46,512 [LocalJobRunner Map Task Executor #0] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\n",
      "2024-01-29 15:53:46,516 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigGenericMapReduce$Map - Aliases being processed per job phase (AliasName[line,offset]): M: FLIGHTS[11,10],FLIGHTS[-1,-1],vuelos_retrasados[17,20],total_retrasos[21,17],contar_retrasos[20,18] C: total_retrasos[21,17],contar_retrasos[20,18] R: total_retrasos[21,17]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-29 15:53:50,453 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - \n",
      "2024-01-29 15:53:50,454 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Starting flush of map output\n",
      "2024-01-29 15:53:50,454 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Spilling map output\n",
      "2024-01-29 15:53:50,454 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 2384890; bufvoid = 104857600\n",
      "2024-01-29 15:53:50,454 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 25260444(101041776); length = 953953/6553600\n",
      "2024-01-29 15:53:50,552 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Finished spill 0\n",
      "2024-01-29 15:53:50,553 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local833473054_0001_m_000001_0 is done. And is in the process of committing\n",
      "2024-01-29 15:53:50,554 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - map\n",
      "2024-01-29 15:53:50,554 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local833473054_0001_m_000001_0' done.\n",
      "2024-01-29 15:53:50,554 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local833473054_0001_m_000001_0: Counters: 18\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=67119346\n",
      "\t\tFILE: Number of bytes written=629581\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=1258869\n",
      "\t\tMap output records=238489\n",
      "\t\tMap output bytes=2384890\n",
      "\t\tMap output materialized bytes=232\n",
      "\t\tInput split bytes=360\n",
      "\t\tCombine input records=238489\n",
      "\t\tCombine output records=16\n",
      "\t\tSpilled Records=16\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=165\n",
      "\t\tTotal committed heap usage (bytes)=602406912\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=0\n",
      "2024-01-29 15:53:50,554 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local833473054_0001_m_000001_0\n",
      "2024-01-29 15:53:50,555 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local833473054_0001_m_000002_0\n",
      "2024-01-29 15:53:50,557 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-01-29 15:53:50,557 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-01-29 15:53:50,558 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2024-01-29 15:53:50,559 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Processing split: Number of splits :1\n",
      "Total Length = 4979249\n",
      "Input split[0]:\n",
      "   Length = 4979249\n",
      "   ClassName: org.apache.hadoop.mapreduce.lib.input.FileSplit\n",
      "   Locations:\n",
      "\n",
      "-----------------------\n",
      "\n",
      "2024-01-29 15:53:50,561 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigRecordReader - Current split being processed file:/media/notebooks/flights.csv:67108864+4979249\n",
      "2024-01-29 15:53:50,564 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)\n",
      "2024-01-29 15:53:50,564 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100\n",
      "2024-01-29 15:53:50,564 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - soft limit at 83886080\n",
      "2024-01-29 15:53:50,564 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600\n",
      "2024-01-29 15:53:50,564 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600\n",
      "2024-01-29 15:53:50,564 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "2024-01-29 15:53:50,575 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.impl.util.SpillableMemoryManager - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128\n",
      "2024-01-29 15:53:50,575 [LocalJobRunner Map Task Executor #0] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\n",
      "2024-01-29 15:53:50,578 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigGenericMapReduce$Map - Aliases being processed per job phase (AliasName[line,offset]): M: FLIGHTS[11,10],FLIGHTS[-1,-1],vuelos_retrasados[17,20],total_retrasos[21,17],contar_retrasos[20,18] C: total_retrasos[21,17],contar_retrasos[20,18] R: total_retrasos[21,17]\n",
      "2024-01-29 15:53:51,209 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - \n",
      "2024-01-29 15:53:51,209 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Starting flush of map output\n",
      "2024-01-29 15:53:51,209 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Spilling map output\n",
      "2024-01-29 15:53:51,209 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 247420; bufvoid = 104857600\n",
      "2024-01-29 15:53:51,209 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26115432(104461728); length = 98965/6553600\n",
      "2024-01-29 15:53:51,235 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Finished spill 0\n",
      "2024-01-29 15:53:51,236 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local833473054_0001_m_000002_0 is done. And is in the process of committing\n",
      "2024-01-29 15:53:51,237 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - map\n",
      "2024-01-29 15:53:51,237 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local833473054_0001_m_000002_0' done.\n",
      "2024-01-29 15:53:51,237 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local833473054_0001_m_000002_0: Counters: 18\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=72099190\n",
      "\t\tFILE: Number of bytes written=629787\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=185864\n",
      "\t\tMap output records=24742\n",
      "\t\tMap output bytes=247420\n",
      "\t\tMap output materialized bytes=174\n",
      "\t\tInput split bytes=360\n",
      "\t\tCombine input records=24742\n",
      "\t\tCombine output records=12\n",
      "\t\tSpilled Records=12\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=109\n",
      "\t\tTotal committed heap usage (bytes)=654311424\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=0\n",
      "2024-01-29 15:53:51,237 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local833473054_0001_m_000002_0\n",
      "2024-01-29 15:53:51,237 [Thread-6] INFO  org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.\n",
      "2024-01-29 15:53:51,239 [Thread-6] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks\n",
      "2024-01-29 15:53:51,239 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local833473054_0001_r_000000_0\n",
      "2024-01-29 15:53:51,248 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-01-29 15:53:51,248 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-01-29 15:53:51,250 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2024-01-29 15:53:51,252 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@67938299\n",
      "2024-01-29 15:53:51,253 [pool-4-thread-1] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-01-29 15:53:51,263 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=652528832, maxSingleShuffleLimit=163132208, mergeThreshold=430669056, ioSortFactor=10, memToMemMergeOutputsThreshold=10\n",
      "2024-01-29 15:53:51,264 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local833473054_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events\n",
      "2024-01-29 15:53:51,280 [localfetcher#1] INFO  org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local833473054_0001_m_000002_0 decomp: 170 len: 174 to MEMORY\n",
      "2024-01-29 15:53:51,282 [localfetcher#1] INFO  org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 170 bytes from map-output for attempt_local833473054_0001_m_000002_0\n",
      "2024-01-29 15:53:51,283 [localfetcher#1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 170, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->170\n",
      "2024-01-29 15:53:51,285 [localfetcher#1] INFO  org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local833473054_0001_m_000000_0 decomp: 230 len: 234 to MEMORY\n",
      "2024-01-29 15:53:51,285 [localfetcher#1] INFO  org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 230 bytes from map-output for attempt_local833473054_0001_m_000000_0\n",
      "2024-01-29 15:53:51,285 [localfetcher#1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 230, inMemoryMapOutputs.size() -> 2, commitMemory -> 170, usedMemory ->400\n",
      "2024-01-29 15:53:51,286 [localfetcher#1] INFO  org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local833473054_0001_m_000001_0 decomp: 228 len: 232 to MEMORY\n",
      "2024-01-29 15:53:51,286 [localfetcher#1] INFO  org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 228 bytes from map-output for attempt_local833473054_0001_m_000001_0\n",
      "2024-01-29 15:53:51,286 [localfetcher#1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 228, inMemoryMapOutputs.size() -> 3, commitMemory -> 400, usedMemory ->628\n",
      "2024-01-29 15:53:51,287 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning\n",
      "2024-01-29 15:53:51,288 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 3 / 3 copied.\n",
      "2024-01-29 15:53:51,288 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs\n",
      "2024-01-29 15:53:51,292 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 3 sorted segments\n",
      "2024-01-29 15:53:51,292 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 3 segments left of total size: 607 bytes\n",
      "2024-01-29 15:53:51,293 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 3 segments, 628 bytes to disk to satisfy reduce memory limit\n",
      "2024-01-29 15:53:51,293 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 628 bytes from disk\n",
      "2024-01-29 15:53:51,294 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce\n",
      "2024-01-29 15:53:51,294 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 1 sorted segments\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-29 15:53:51,294 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 617 bytes\n",
      "2024-01-29 15:53:51,294 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 3 / 3 copied.\n",
      "2024-01-29 15:53:51,299 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-01-29 15:53:51,299 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-01-29 15:53:51,301 [pool-4-thread-1] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords\n",
      "2024-01-29 15:53:51,301 [pool-4-thread-1] INFO  org.apache.pig.impl.util.SpillableMemoryManager - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128\n",
      "2024-01-29 15:53:51,302 [pool-4-thread-1] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\n",
      "2024-01-29 15:53:51,303 [pool-4-thread-1] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigMapReduce$Reduce - Aliases being processed per job phase (AliasName[line,offset]): M: FLIGHTS[11,10],FLIGHTS[-1,-1],vuelos_retrasados[17,20],total_retrasos[21,17],contar_retrasos[20,18] C: total_retrasos[21,17],contar_retrasos[20,18] R: total_retrasos[21,17]\n",
      "2024-01-29 15:53:51,306 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local833473054_0001_r_000000_0 is done. And is in the process of committing\n",
      "2024-01-29 15:53:51,308 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 3 / 3 copied.\n",
      "2024-01-29 15:53:51,308 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task - Task attempt_local833473054_0001_r_000000_0 is allowed to commit now\n",
      "2024-01-29 15:53:51,310 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local833473054_0001_r_000000_0' to file:/tmp/temp-856879477/tmp1745559430\n",
      "2024-01-29 15:53:51,311 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce\n",
      "2024-01-29 15:53:51,311 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local833473054_0001_r_000000_0' done.\n",
      "2024-01-29 15:53:51,311 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local833473054_0001_r_000000_0: Counters: 24\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=72100554\n",
      "\t\tFILE: Number of bytes written=630631\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=16\n",
      "\t\tReduce shuffle bytes=640\n",
      "\t\tReduce input records=44\n",
      "\t\tReduce output records=16\n",
      "\t\tSpilled Records=44\n",
      "\t\tShuffled Maps =3\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=3\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=654311424\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=0\n",
      "2024-01-29 15:53:51,311 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local833473054_0001_r_000000_0\n",
      "2024-01-29 15:53:51,311 [Thread-6] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.\n",
      "2024-01-29 15:53:51,457 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 25% complete\n",
      "2024-01-29 15:53:51,459 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-01-29 15:53:51,468 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-01-29 15:53:51,469 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps\n",
      "2024-01-29 15:53:51,469 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-01-29 15:53:51,482 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState - Pig script settings are added to the job\n",
      "2024-01-29 15:53:51,482 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3\n",
      "2024-01-29 15:53:51,482 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Reduce phase detected, estimating # of required reducers.\n",
      "2024-01-29 15:53:51,483 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Using reducer estimator: org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.InputSizeReducerEstimator\n",
      "2024-01-29 15:53:51,483 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.InputSizeReducerEstimator - BytesPerReducer=1000000000 maxReducers=999 totalInputFileSize=204\n",
      "2024-01-29 15:53:51,484 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Setting Parallelism to 1\n",
      "2024-01-29 15:53:51,485 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Setting up single store job\n",
      "2024-01-29 15:53:51,498 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 1 map-reduce job(s) waiting for submission.\n",
      "2024-01-29 15:53:51,500 [JobControl] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-01-29 15:53:51,505 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
      "2024-01-29 15:53:51,509 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2024-01-29 15:53:51,509 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths to process : 1\n",
      "2024-01-29 15:53:51,509 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths (combined) to process : 1\n",
      "2024-01-29 15:53:51,511 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1\n",
      "2024-01-29 15:53:51,518 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1379808152_0002\n",
      "2024-01-29 15:53:51,519 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Executing with tokens: []\n",
      "2024-01-29 15:53:51,573 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/\n",
      "2024-01-29 15:53:51,574 [Thread-17] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null\n",
      "2024-01-29 15:53:51,577 [Thread-17] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces\n",
      "2024-01-29 15:53:51,577 [Thread-17] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address\n",
      "2024-01-29 15:53:51,577 [Thread-17] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.reduce.markreset.buffer.percent is deprecated. Instead, use mapreduce.reduce.markreset.buffer.percent\n",
      "2024-01-29 15:53:51,578 [Thread-17] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-01-29 15:53:51,578 [Thread-17] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-01-29 15:53:51,578 [Thread-17] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigOutputCommitter\n",
      "2024-01-29 15:53:51,582 [Thread-17] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks\n",
      "2024-01-29 15:53:51,582 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1379808152_0002_m_000000_0\n",
      "2024-01-29 15:53:51,587 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-01-29 15:53:51,587 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-01-29 15:53:51,587 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2024-01-29 15:53:51,588 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Processing split: Number of splits :1\n",
      "Total Length = 204\n",
      "Input split[0]:\n",
      "   Length = 204\n",
      "   ClassName: org.apache.hadoop.mapreduce.lib.input.FileSplit\n",
      "   Locations:\n",
      "\n",
      "-----------------------\n",
      "\n",
      "2024-01-29 15:53:51,593 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigRecordReader - Current split being processed file:/tmp/temp-856879477/tmp1745559430/part-r-00000:0+204\n",
      "2024-01-29 15:53:51,596 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)\n",
      "2024-01-29 15:53:51,596 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100\n",
      "2024-01-29 15:53:51,596 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - soft limit at 83886080\n",
      "2024-01-29 15:53:51,596 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600\n",
      "2024-01-29 15:53:51,596 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600\n",
      "2024-01-29 15:53:51,598 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-29 15:53:51,601 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.impl.util.SpillableMemoryManager - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128\r\n",
      "2024-01-29 15:53:51,601 [LocalJobRunner Map Task Executor #0] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\r\n",
      "2024-01-29 15:53:51,602 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigGenericMapReduce$Map - Aliases being processed per job phase (AliasName[line,offset]): M: top5_retrasos[24,16] C:  R: \r\n",
      "2024-01-29 15:53:51,603 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - \r\n",
      "2024-01-29 15:53:51,603 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Starting flush of map output\r\n",
      "2024-01-29 15:53:51,603 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Spilling map output\r\n",
      "2024-01-29 15:53:51,603 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 312; bufvoid = 104857600\r\n",
      "2024-01-29 15:53:51,603 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214336(104857344); length = 61/6553600\r\n",
      "2024-01-29 15:53:51,606 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Finished spill 0\r\n",
      "2024-01-29 15:53:51,607 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local1379808152_0002_m_000000_0 is done. And is in the process of committing\r\n",
      "2024-01-29 15:53:51,608 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - map\r\n",
      "2024-01-29 15:53:51,608 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local1379808152_0002_m_000000_0' done.\r\n",
      "2024-01-29 15:53:51,609 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local1379808152_0002_m_000000_0: Counters: 17\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=72101207\r\n",
      "\t\tFILE: Number of bytes written=1245349\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=16\r\n",
      "\t\tMap output records=16\r\n",
      "\t\tMap output bytes=312\r\n",
      "\t\tMap output materialized bytes=350\r\n",
      "\t\tInput split bytes=378\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=16\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=654311424\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=0\r\n",
      "2024-01-29 15:53:51,609 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1379808152_0002_m_000000_0\r\n",
      "2024-01-29 15:53:51,609 [Thread-17] INFO  org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.\r\n",
      "2024-01-29 15:53:51,609 [Thread-17] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks\r\n",
      "2024-01-29 15:53:51,609 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1379808152_0002_r_000000_0\r\n",
      "2024-01-29 15:53:51,615 [pool-9-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\r\n",
      "2024-01-29 15:53:51,615 [pool-9-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "2024-01-29 15:53:51,616 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "2024-01-29 15:53:51,616 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@298aca6e\r\n",
      "2024-01-29 15:53:51,617 [pool-9-thread-1] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\r\n",
      "2024-01-29 15:53:51,617 [pool-9-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=652528832, maxSingleShuffleLimit=163132208, mergeThreshold=430669056, ioSortFactor=10, memToMemMergeOutputsThreshold=10\r\n",
      "2024-01-29 15:53:51,618 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1379808152_0002_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events\r\n",
      "2024-01-29 15:53:51,619 [localfetcher#2] INFO  org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#2 about to shuffle output of map attempt_local1379808152_0002_m_000000_0 decomp: 346 len: 350 to MEMORY\r\n",
      "2024-01-29 15:53:51,619 [localfetcher#2] INFO  org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 346 bytes from map-output for attempt_local1379808152_0002_m_000000_0\r\n",
      "2024-01-29 15:53:51,620 [localfetcher#2] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 346, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->346\r\n",
      "2024-01-29 15:53:51,620 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning\r\n",
      "2024-01-29 15:53:51,621 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\r\n",
      "2024-01-29 15:53:51,621 [pool-9-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs\r\n",
      "2024-01-29 15:53:51,622 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 1 sorted segments\r\n",
      "2024-01-29 15:53:51,623 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 330 bytes\r\n",
      "2024-01-29 15:53:51,623 [pool-9-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 346 bytes to disk to satisfy reduce memory limit\r\n",
      "2024-01-29 15:53:51,624 [pool-9-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 350 bytes from disk\r\n",
      "2024-01-29 15:53:51,624 [pool-9-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce\r\n",
      "2024-01-29 15:53:51,624 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 1 sorted segments\r\n",
      "2024-01-29 15:53:51,624 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 330 bytes\r\n",
      "2024-01-29 15:53:51,624 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\r\n",
      "2024-01-29 15:53:51,626 [pool-9-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\r\n",
      "2024-01-29 15:53:51,626 [pool-9-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "2024-01-29 15:53:51,628 [pool-9-thread-1] INFO  org.apache.pig.impl.util.SpillableMemoryManager - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128\r\n",
      "2024-01-29 15:53:51,628 [pool-9-thread-1] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\r\n",
      "2024-01-29 15:53:51,630 [pool-9-thread-1] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigMapReduce$Reduce - Aliases being processed per job phase (AliasName[line,offset]): M: top5_retrasos[24,16] C:  R: \r\n",
      "2024-01-29 15:53:51,633 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local1379808152_0002_r_000000_0 is done. And is in the process of committing\r\n",
      "2024-01-29 15:53:51,635 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\r\n",
      "2024-01-29 15:53:51,635 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.Task - Task attempt_local1379808152_0002_r_000000_0 is allowed to commit now\r\n",
      "2024-01-29 15:53:51,637 [pool-9-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1379808152_0002_r_000000_0' to file:/tmp/temp-856879477/tmp-780021672\r\n",
      "2024-01-29 15:53:51,637 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce\r\n",
      "2024-01-29 15:53:51,637 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local1379808152_0002_r_000000_0' done.\r\n",
      "2024-01-29 15:53:51,637 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local1379808152_0002_r_000000_0: Counters: 24\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=72101939\r\n",
      "\t\tFILE: Number of bytes written=1245762\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tCombine output records=0\r\n",
      "\t\tReduce input groups=1\r\n",
      "\t\tReduce shuffle bytes=350\r\n",
      "\t\tReduce input records=16\r\n",
      "\t\tReduce output records=1\r\n",
      "\t\tSpilled Records=16\r\n",
      "\t\tShuffled Maps =1\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=1\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=654311424\r\n",
      "\tShuffle Errors\r\n",
      "\t\tBAD_ID=0\r\n",
      "\t\tCONNECTION=0\r\n",
      "\t\tIO_ERROR=0\r\n",
      "\t\tWRONG_LENGTH=0\r\n",
      "\t\tWRONG_MAP=0\r\n",
      "\t\tWRONG_REDUCE=0\r\n",
      "\tFile Output Format Counters \r\n",
      "\t\tBytes Written=0\r\n",
      "2024-01-29 15:53:51,637 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1379808152_0002_r_000000_0\r\n",
      "2024-01-29 15:53:51,638 [Thread-17] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-29 15:53:51,774 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - HadoopJobId: job_local1379808152_0002\n",
      "2024-01-29 15:53:51,774 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - Processing aliases top5_retrasos\n",
      "2024-01-29 15:53:51,774 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - detailed locations: M: top5_retrasos[24,16] C:  R: \n",
      "2024-01-29 15:53:51,775 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 50% complete\n",
      "2024-01-29 15:53:51,776 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-01-29 15:53:51,777 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-01-29 15:53:51,778 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-01-29 15:53:51,781 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState - Pig script settings are added to the job\n",
      "2024-01-29 15:53:51,782 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3\n",
      "2024-01-29 15:53:51,782 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Reduce phase detected, estimating # of required reducers.\n",
      "2024-01-29 15:53:51,782 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Setting Parallelism to 1\n",
      "2024-01-29 15:53:51,783 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Setting up single store job\n",
      "2024-01-29 15:53:51,796 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 1 map-reduce job(s) waiting for submission.\n",
      "2024-01-29 15:53:51,797 [JobControl] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-01-29 15:53:51,802 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
      "2024-01-29 15:53:51,804 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2024-01-29 15:53:51,804 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths to process : 1\n",
      "2024-01-29 15:53:51,804 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths (combined) to process : 1\n",
      "2024-01-29 15:53:51,805 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1\n",
      "2024-01-29 15:53:51,816 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1629033974_0003\n",
      "2024-01-29 15:53:51,816 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Executing with tokens: []\n",
      "2024-01-29 15:53:51,858 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/\n",
      "2024-01-29 15:53:51,859 [Thread-24] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null\n",
      "2024-01-29 15:53:51,863 [Thread-24] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces\n",
      "2024-01-29 15:53:51,863 [Thread-24] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address\n",
      "2024-01-29 15:53:51,863 [Thread-24] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.reduce.markreset.buffer.percent is deprecated. Instead, use mapreduce.reduce.markreset.buffer.percent\n",
      "2024-01-29 15:53:51,863 [Thread-24] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-01-29 15:53:51,863 [Thread-24] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-01-29 15:53:51,863 [Thread-24] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigOutputCommitter\n",
      "2024-01-29 15:53:51,867 [Thread-24] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks\n",
      "2024-01-29 15:53:51,867 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1629033974_0003_m_000000_0\n",
      "2024-01-29 15:53:51,872 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-01-29 15:53:51,872 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-01-29 15:53:51,872 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2024-01-29 15:53:51,873 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Processing split: Number of splits :1\n",
      "Total Length = 204\n",
      "Input split[0]:\n",
      "   Length = 204\n",
      "   ClassName: org.apache.hadoop.mapreduce.lib.input.FileSplit\n",
      "   Locations:\n",
      "\n",
      "-----------------------\n",
      "\n",
      "2024-01-29 15:53:51,874 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigRecordReader - Current split being processed file:/tmp/temp-856879477/tmp1745559430/part-r-00000:0+204\n",
      "2024-01-29 15:53:51,877 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)\n",
      "2024-01-29 15:53:51,877 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100\n",
      "2024-01-29 15:53:51,877 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - soft limit at 83886080\n",
      "2024-01-29 15:53:51,877 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600\n",
      "2024-01-29 15:53:51,877 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600\n",
      "2024-01-29 15:53:51,878 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "2024-01-29 15:53:51,879 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.impl.util.SpillableMemoryManager - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128\n",
      "2024-01-29 15:53:51,879 [LocalJobRunner Map Task Executor #0] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\n",
      "2024-01-29 15:53:51,880 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigGenericMapReduce$Map - Aliases being processed per job phase (AliasName[line,offset]): M: top5_retrasos[24,16] C:  R: \n",
      "2024-01-29 15:53:51,881 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - \n",
      "2024-01-29 15:53:51,881 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Starting flush of map output\n",
      "2024-01-29 15:53:51,881 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Spilling map output\n",
      "2024-01-29 15:53:51,881 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 288; bufvoid = 104857600\n",
      "2024-01-29 15:53:51,881 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214336(104857344); length = 61/6553600\n",
      "2024-01-29 15:53:51,887 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Finished spill 0\n",
      "2024-01-29 15:53:51,888 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local1629033974_0003_m_000000_0 is done. And is in the process of committing\n",
      "2024-01-29 15:53:51,889 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - map\n",
      "2024-01-29 15:53:51,889 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local1629033974_0003_m_000000_0' done.\n",
      "2024-01-29 15:53:51,889 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local1629033974_0003_m_000000_0: Counters: 18\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=72102592\n",
      "\t\tFILE: Number of bytes written=1866797\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=16\n",
      "\t\tMap output records=16\n",
      "\t\tMap output bytes=288\n",
      "\t\tMap output materialized bytes=106\n",
      "\t\tInput split bytes=378\n",
      "\t\tCombine input records=16\n",
      "\t\tCombine output records=5\n",
      "\t\tSpilled Records=5\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=654311424\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=0\n",
      "2024-01-29 15:53:51,889 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1629033974_0003_m_000000_0\n",
      "2024-01-29 15:53:51,889 [Thread-24] INFO  org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.\n",
      "2024-01-29 15:53:51,890 [Thread-24] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks\n",
      "2024-01-29 15:53:51,890 [pool-12-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1629033974_0003_r_000000_0\n",
      "2024-01-29 15:53:51,895 [pool-12-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-01-29 15:53:51,895 [pool-12-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-01-29 15:53:51,896 [pool-12-thread-1] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2024-01-29 15:53:51,896 [pool-12-thread-1] INFO  org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@475b975\n",
      "2024-01-29 15:53:51,896 [pool-12-thread-1] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-01-29 15:53:51,897 [pool-12-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=652528832, maxSingleShuffleLimit=163132208, mergeThreshold=430669056, ioSortFactor=10, memToMemMergeOutputsThreshold=10\n",
      "2024-01-29 15:53:51,898 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1629033974_0003_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events\n",
      "2024-01-29 15:53:51,899 [localfetcher#3] INFO  org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#3 about to shuffle output of map attempt_local1629033974_0003_m_000000_0 decomp: 102 len: 106 to MEMORY\n",
      "2024-01-29 15:53:51,899 [localfetcher#3] INFO  org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 102 bytes from map-output for attempt_local1629033974_0003_m_000000_0\n",
      "2024-01-29 15:53:51,899 [localfetcher#3] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 102, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->102\n",
      "2024-01-29 15:53:51,900 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning\n",
      "2024-01-29 15:53:51,900 [pool-12-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2024-01-29 15:53:51,900 [pool-12-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs\n",
      "2024-01-29 15:53:51,902 [pool-12-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 1 sorted segments\n",
      "2024-01-29 15:53:51,902 [pool-12-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 90 bytes\n",
      "2024-01-29 15:53:51,902 [pool-12-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 102 bytes to disk to satisfy reduce memory limit\n",
      "2024-01-29 15:53:51,902 [pool-12-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 106 bytes from disk\n",
      "2024-01-29 15:53:51,902 [pool-12-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce\n",
      "2024-01-29 15:53:51,902 [pool-12-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 1 sorted segments\n",
      "2024-01-29 15:53:51,903 [pool-12-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 90 bytes\n",
      "2024-01-29 15:53:51,903 [pool-12-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2024-01-29 15:53:51,904 [pool-12-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-29 15:53:51,904 [pool-12-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-01-29 15:53:51,906 [pool-12-thread-1] INFO  org.apache.pig.impl.util.SpillableMemoryManager - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128\n",
      "2024-01-29 15:53:51,906 [pool-12-thread-1] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\n",
      "2024-01-29 15:53:51,907 [pool-12-thread-1] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigMapReduce$Reduce - Aliases being processed per job phase (AliasName[line,offset]): M: top5_retrasos[24,16] C:  R: \n",
      "2024-01-29 15:53:51,908 [pool-12-thread-1] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local1629033974_0003_r_000000_0 is done. And is in the process of committing\n",
      "2024-01-29 15:53:51,909 [pool-12-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2024-01-29 15:53:51,909 [pool-12-thread-1] INFO  org.apache.hadoop.mapred.Task - Task attempt_local1629033974_0003_r_000000_0 is allowed to commit now\n",
      "2024-01-29 15:53:51,911 [pool-12-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1629033974_0003_r_000000_0' to file:/tmp/temp-856879477/tmp487832794\n",
      "2024-01-29 15:53:51,911 [pool-12-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce\n",
      "2024-01-29 15:53:51,911 [pool-12-thread-1] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local1629033974_0003_r_000000_0' done.\n",
      "2024-01-29 15:53:51,911 [pool-12-thread-1] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local1629033974_0003_r_000000_0: Counters: 24\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=72102836\n",
      "\t\tFILE: Number of bytes written=1866985\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=5\n",
      "\t\tReduce shuffle bytes=106\n",
      "\t\tReduce input records=5\n",
      "\t\tReduce output records=5\n",
      "\t\tSpilled Records=5\n",
      "\t\tShuffled Maps =1\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=1\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=654311424\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=0\n",
      "2024-01-29 15:53:51,912 [pool-12-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1629033974_0003_r_000000_0\n",
      "2024-01-29 15:53:51,912 [Thread-24] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.\n",
      "2024-01-29 15:53:52,059 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - HadoopJobId: job_local1629033974_0003\n",
      "2024-01-29 15:53:52,059 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - Processing aliases top5_retrasos\n",
      "2024-01-29 15:53:52,059 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - detailed locations: M: top5_retrasos[24,16] C:  R: \n",
      "2024-01-29 15:53:52,060 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 75% complete\n",
      "2024-01-29 15:53:52,061 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-01-29 15:53:52,062 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-01-29 15:53:52,063 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-01-29 15:53:52,066 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState - Pig script settings are added to the job\n",
      "2024-01-29 15:53:52,066 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3\n",
      "2024-01-29 15:53:52,067 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Reduce phase detected, estimating # of required reducers.\n",
      "2024-01-29 15:53:52,067 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Setting Parallelism to 1\n",
      "2024-01-29 15:53:52,068 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Setting up single store job\n",
      "2024-01-29 15:53:52,076 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 1 map-reduce job(s) waiting for submission.\n",
      "2024-01-29 15:53:52,077 [JobControl] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-01-29 15:53:52,081 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
      "2024-01-29 15:53:52,082 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2024-01-29 15:53:52,082 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths to process : 1\n",
      "2024-01-29 15:53:52,082 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths (combined) to process : 1\n",
      "2024-01-29 15:53:52,084 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1\n",
      "2024-01-29 15:53:52,092 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1079288087_0004\n",
      "2024-01-29 15:53:52,092 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Executing with tokens: []\n",
      "2024-01-29 15:53:52,135 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/\n",
      "2024-01-29 15:53:52,135 [Thread-31] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null\n",
      "2024-01-29 15:53:52,139 [Thread-31] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces\n",
      "2024-01-29 15:53:52,139 [Thread-31] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address\n",
      "2024-01-29 15:53:52,139 [Thread-31] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.reduce.markreset.buffer.percent is deprecated. Instead, use mapreduce.reduce.markreset.buffer.percent\n",
      "2024-01-29 15:53:52,139 [Thread-31] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-01-29 15:53:52,139 [Thread-31] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-01-29 15:53:52,139 [Thread-31] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigOutputCommitter\n",
      "2024-01-29 15:53:52,143 [Thread-31] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks\n",
      "2024-01-29 15:53:52,143 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1079288087_0004_m_000000_0\n",
      "2024-01-29 15:53:52,148 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-01-29 15:53:52,148 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-01-29 15:53:52,148 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2024-01-29 15:53:52,149 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Processing split: Number of splits :1\n",
      "Total Length = 70\n",
      "Input split[0]:\n",
      "   Length = 70\n",
      "   ClassName: org.apache.hadoop.mapreduce.lib.input.FileSplit\n",
      "   Locations:\n",
      "\n",
      "-----------------------\n",
      "\n",
      "2024-01-29 15:53:52,150 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigRecordReader - Current split being processed file:/tmp/temp-856879477/tmp487832794/part-r-00000:0+70\n",
      "2024-01-29 15:53:52,152 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)\n",
      "2024-01-29 15:53:52,152 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100\n",
      "2024-01-29 15:53:52,152 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - soft limit at 83886080\n",
      "2024-01-29 15:53:52,152 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600\n",
      "2024-01-29 15:53:52,153 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600\n",
      "2024-01-29 15:53:52,153 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "2024-01-29 15:53:52,154 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.impl.util.SpillableMemoryManager - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128\n",
      "2024-01-29 15:53:52,154 [LocalJobRunner Map Task Executor #0] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\n",
      "2024-01-29 15:53:52,154 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigGenericMapReduce$Map - Aliases being processed per job phase (AliasName[line,offset]): M: top5_retrasos[24,16] C:  R: \n",
      "2024-01-29 15:53:52,155 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - \n",
      "2024-01-29 15:53:52,155 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Starting flush of map output\n",
      "2024-01-29 15:53:52,155 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Spilling map output\n",
      "2024-01-29 15:53:52,155 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 90; bufvoid = 104857600\n",
      "2024-01-29 15:53:52,155 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214380(104857520); length = 17/6553600\n",
      "2024-01-29 15:53:52,157 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Finished spill 0\n",
      "2024-01-29 15:53:52,157 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local1079288087_0004_m_000000_0 is done. And is in the process of committing\n",
      "2024-01-29 15:53:52,158 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - map\n",
      "2024-01-29 15:53:52,158 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local1079288087_0004_m_000000_0' done.\n",
      "2024-01-29 15:53:52,158 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local1079288087_0004_m_000000_0: Counters: 17\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=72103353\n",
      "\t\tFILE: Number of bytes written=2475549\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=5\n",
      "\t\tMap output records=5\n",
      "\t\tMap output bytes=90\n",
      "\t\tMap output materialized bytes=106\n",
      "\t\tInput split bytes=377\n",
      "\t\tCombine input records=0\n",
      "\t\tSpilled Records=5\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=654311424\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=0\n",
      "2024-01-29 15:53:52,158 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1079288087_0004_m_000000_0\n",
      "2024-01-29 15:53:52,158 [Thread-31] INFO  org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.\n",
      "2024-01-29 15:53:52,159 [Thread-31] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks\n",
      "2024-01-29 15:53:52,159 [pool-15-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1079288087_0004_r_000000_0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-29 15:53:52,164 [pool-15-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-01-29 15:53:52,164 [pool-15-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-01-29 15:53:52,165 [pool-15-thread-1] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2024-01-29 15:53:52,165 [pool-15-thread-1] INFO  org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@4f8e16\n",
      "2024-01-29 15:53:52,165 [pool-15-thread-1] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-01-29 15:53:52,166 [pool-15-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=652528832, maxSingleShuffleLimit=163132208, mergeThreshold=430669056, ioSortFactor=10, memToMemMergeOutputsThreshold=10\n",
      "2024-01-29 15:53:52,167 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1079288087_0004_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events\n",
      "2024-01-29 15:53:52,168 [localfetcher#4] INFO  org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#4 about to shuffle output of map attempt_local1079288087_0004_m_000000_0 decomp: 102 len: 106 to MEMORY\n",
      "2024-01-29 15:53:52,168 [localfetcher#4] INFO  org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 102 bytes from map-output for attempt_local1079288087_0004_m_000000_0\n",
      "2024-01-29 15:53:52,168 [localfetcher#4] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 102, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->102\n",
      "2024-01-29 15:53:52,168 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning\n",
      "2024-01-29 15:53:52,169 [pool-15-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2024-01-29 15:53:52,169 [pool-15-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs\n",
      "2024-01-29 15:53:52,171 [pool-15-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 1 sorted segments\n",
      "2024-01-29 15:53:52,171 [pool-15-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 90 bytes\n",
      "2024-01-29 15:53:52,171 [pool-15-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 102 bytes to disk to satisfy reduce memory limit\n",
      "2024-01-29 15:53:52,171 [pool-15-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 106 bytes from disk\n",
      "2024-01-29 15:53:52,171 [pool-15-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce\n",
      "2024-01-29 15:53:52,171 [pool-15-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 1 sorted segments\n",
      "2024-01-29 15:53:52,172 [pool-15-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 90 bytes\n",
      "2024-01-29 15:53:52,172 [pool-15-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2024-01-29 15:53:52,173 [pool-15-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-01-29 15:53:52,173 [pool-15-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-01-29 15:53:52,175 [pool-15-thread-1] INFO  org.apache.pig.impl.util.SpillableMemoryManager - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128\n",
      "2024-01-29 15:53:52,175 [pool-15-thread-1] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\n",
      "2024-01-29 15:53:52,176 [pool-15-thread-1] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigMapReduce$Reduce - Aliases being processed per job phase (AliasName[line,offset]): M: top5_retrasos[24,16] C:  R: \n",
      "2024-01-29 15:53:52,177 [pool-15-thread-1] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local1079288087_0004_r_000000_0 is done. And is in the process of committing\n",
      "2024-01-29 15:53:52,178 [pool-15-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2024-01-29 15:53:52,178 [pool-15-thread-1] INFO  org.apache.hadoop.mapred.Task - Task attempt_local1079288087_0004_r_000000_0 is allowed to commit now\n",
      "2024-01-29 15:53:52,179 [pool-15-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1079288087_0004_r_000000_0' to file:/tmp/temp-856879477/tmp-1179730717\n",
      "2024-01-29 15:53:52,180 [pool-15-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce\n",
      "2024-01-29 15:53:52,180 [pool-15-thread-1] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local1079288087_0004_r_000000_0' done.\n",
      "2024-01-29 15:53:52,180 [pool-15-thread-1] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local1079288087_0004_r_000000_0: Counters: 24\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=72103597\n",
      "\t\tFILE: Number of bytes written=2475737\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=5\n",
      "\t\tReduce shuffle bytes=106\n",
      "\t\tReduce input records=5\n",
      "\t\tReduce output records=5\n",
      "\t\tSpilled Records=5\n",
      "\t\tShuffled Maps =1\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=1\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=654311424\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=0\n",
      "2024-01-29 15:53:52,180 [pool-15-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1079288087_0004_r_000000_0\n",
      "2024-01-29 15:53:52,180 [Thread-31] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.\n",
      "2024-01-29 15:53:52,335 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - HadoopJobId: job_local1079288087_0004\n",
      "2024-01-29 15:53:52,336 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - Processing aliases top5_retrasos\n",
      "2024-01-29 15:53:52,336 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - detailed locations: M: top5_retrasos[24,16] C:  R: \n",
      "2024-01-29 15:53:52,337 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-01-29 15:53:52,338 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-01-29 15:53:52,339 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-01-29 15:53:52,342 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 100% complete\n",
      "2024-01-29 15:53:52,345 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.SimplePigStats - Script Statistics: \n",
      "\n",
      "HadoopVersion\tPigVersion\tUserId\tStartedAt\tFinishedAt\tFeatures\n",
      "3.3.1\t0.17.0\troot\t2024-01-29 15:53:41\t2024-01-29 15:53:52\tGROUP_BY,ORDER_BY,FILTER,LIMIT\n",
      "\n",
      "Success!\n",
      "\n",
      "Job Stats (time in seconds):\n",
      "JobId\tMaps\tReduces\tMaxMapTime\tMinMapTime\tAvgMapTime\tMedianMapTime\tMaxReduceTime\tMinReduceTime\tAvgReduceTime\tMedianReducetime\tAlias\tFeature\tOutputs\n",
      "job_local1079288087_0004\t1\t1\tn/a\tn/a\tn/a\tn/a\tn/a\tn/a\tn/a\tn/a\ttop5_retrasos\t\tfile:/tmp/temp-856879477/tmp-1179730717,\n",
      "job_local1379808152_0002\t1\t1\tn/a\tn/a\tn/a\tn/a\tn/a\tn/a\tn/a\tn/a\ttop5_retrasos\tSAMPLER\t\n",
      "job_local1629033974_0003\t1\t1\tn/a\tn/a\tn/a\tn/a\tn/a\tn/a\tn/a\tn/a\ttop5_retrasos\tORDER_BY,COMBINER\t\n",
      "job_local833473054_0001\t3\t1\tn/a\tn/a\tn/a\tn/a\tn/a\tn/a\tn/a\tn/a\tFLIGHTS,contar_retrasos,total_retrasos,vuelos_retrasados\tGROUP_BY,COMBINER\t\n",
      "\n",
      "Input(s):\n",
      "Successfully read 2702218 records from: \"file:///media/notebooks/flights.csv\"\n",
      "\n",
      "Output(s):\n",
      "Successfully stored 5 records in: \"file:/tmp/temp-856879477/tmp-1179730717\"\n",
      "\n",
      "Counters:\n",
      "Total records written : 5\n",
      "Total bytes written : 0\n",
      "Spillable Memory Manager spill count : 0\n",
      "Total bags proactively spilled: 0\n",
      "Total records proactively spilled: 0\n",
      "\n",
      "Job DAG:\n",
      "job_local833473054_0001\t->\tjob_local1379808152_0002,\n",
      "job_local1379808152_0002\t->\tjob_local1629033974_0003,\n",
      "job_local1629033974_0003\t->\tjob_local1079288087_0004,\n",
      "job_local1079288087_0004\n",
      "\n",
      "\n",
      "2024-01-29 15:53:52,346 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-01-29 15:53:52,347 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-01-29 15:53:52,348 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-01-29 15:53:52,351 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-01-29 15:53:52,352 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-01-29 15:53:52,352 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-01-29 15:53:52,354 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-01-29 15:53:52,355 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-01-29 15:53:52,356 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-01-29 15:53:52,358 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-01-29 15:53:52,359 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-01-29 15:53:52,359 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-01-29 15:53:52,361 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - Success!\n",
      "2024-01-29 15:53:52,363 [main] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-29 15:53:52,364 [main] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2024-01-29 15:53:52,364 [main] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths to process : 1\n",
      "(WN,127601)\n",
      "(AA,59842)\n",
      "(DL,57668)\n",
      "(UA,57367)\n",
      "(US,40943)\n",
      "2024-01-29 15:53:52,426 [main] INFO  org.apache.pig.Main - Pig script completed in 11 seconds and 635 milliseconds (11635 ms)\n"
     ]
    }
   ],
   "source": [
    "! pig -x local -f delayed_flights.pig -param airports_file='airports.csv' -param flights_file='flights.csv' -param output_dir='pig/output/flights'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.- Resuelve el ejercicio 3 con Pig Latin\n",
    "\n",
    "Se espera el siguiente resultado:\n",
    "\n",
    "![solución 5](./img/5.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting company_recover.pig\n"
     ]
    }
   ],
   "source": [
    "%%writefile company_recover.pig\n",
    "\n",
    "-- registro de la librería PiggyBank\n",
    "REGISTER piggybank.jar\n",
    "\n",
    "-- Lectura CSV\n",
    "\n",
    "AIRPORTS = LOAD '$airports_file' USING\n",
    "    org.apache.pig.piggybank.storage.CSVExcelStorage(',','NO_MULTILINE','UNIX','SKIP_INPUT_HEADER')\n",
    "    AS (airportid:chararray, city:chararray, state:chararray, airportname:chararray);\n",
    "\n",
    "FLIGHTS = LOAD '$flights_file' USING\n",
    "    org.apache.pig.piggybank.storage.CSVExcelStorage(',','NO_MULTILINE','UNIX','SKIP_INPUT_HEADER')\n",
    "    AS (dayofmonth:int, dayofweek:int, carrier:chararray,\n",
    "           depairport:chararray, arrairportid:chararray, depdelay:int, arrdelay:int);\n",
    "\n",
    "-- Seleccionamos los vuelos retrasados\n",
    "vuelos_retrasados = FILTER FLIGHTS BY depdelay > 15;\n",
    "\n",
    "-- Seleccionamos los vuelos retrasados que llegaron sin retraso\n",
    "vuelos_recuperados = FILTER vuelos_retrasados BY arrdelay <= 15;\n",
    "\n",
    "-- Contamos los vuelos recuperados por cada compañía\n",
    "contar_recuperados = GROUP vuelos_recuperados BY carrier;\n",
    "total_recuperados = FOREACH contar_recuperados GENERATE group AS carrier, COUNT(vuelos_recuperados) AS vuelos_recuperados;\n",
    "\n",
    "-- Contamos los vuelos retrasados por cada compañía\n",
    "contar_retrasos = GROUP vuelos_retrasados BY carrier;\n",
    "total_retrasos = FOREACH contar_retrasos GENERATE group AS carrier, COUNT(vuelos_retrasados) AS total_retrasos;\n",
    "\n",
    "-- Calcular porcentaje de recuperación\n",
    "recover = JOIN total_recuperados BY carrier, total_retrasos BY carrier;\n",
    "recover = FOREACH recover GENERATE\n",
    "    $0 AS carrier,\n",
    "    ($1 * 1.0 / $3) AS recover;\n",
    "\n",
    "-- Ordenar y limitar a 5 compañías\n",
    "top5 = ORDER recover BY recover DESC;\n",
    "top5 = LIMIT top5 5;\n",
    "\n",
    "-- DUMP del TOP5\n",
    "DUMP top5;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-29 17:07:59,858 INFO pig.ExecTypeProvider: Trying ExecType : LOCAL\n",
      "2024-01-29 17:07:59,858 INFO pig.ExecTypeProvider: Picked LOCAL as the ExecType\n",
      "2024-01-29 17:07:59,895 [main] INFO  org.apache.pig.Main - Apache Pig version 0.17.0 (r1797386) compiled Jun 02 2017, 15:41:58\n",
      "2024-01-29 17:07:59,895 [main] INFO  org.apache.pig.Main - Logging error messages to: /media/notebooks/pig_1706544479893.log\n",
      "2024-01-29 17:07:59,904 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - user.name is deprecated. Instead, use mapreduce.job.user.name\n",
      "2024-01-29 17:08:00,009 [main] INFO  org.apache.pig.impl.util.Utils - Default bootup file /root/.pigbootup not found\n",
      "2024-01-29 17:08:00,057 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address\n",
      "2024-01-29 17:08:00,058 [main] INFO  org.apache.pig.backend.hadoop.executionengine.HExecutionEngine - Connecting to hadoop file system at: file:///\n",
      "2024-01-29 17:08:00,073 [main] INFO  org.apache.pig.PigServer - Pig Script ID for the session: PIG-company_recover.pig-98ef5119-83bf-4f18-be9d-eda7dc01e815\n",
      "2024-01-29 17:08:00,073 [main] WARN  org.apache.pig.PigServer - ATS is disabled since yarn.timeline-service.enabled set to false\n",
      "2024-01-29 17:08:00,616 [main] WARN  org.apache.pig.newplan.BaseOperatorPlan - Encountered Warning IMPLICIT_CAST_TO_DOUBLE 2 time(s).\n",
      "2024-01-29 17:08:00,621 [main] INFO  org.apache.pig.tools.pigstats.ScriptState - Pig features used in the script: HASH_JOIN,GROUP_BY,ORDER_BY,FILTER,LIMIT\n",
      "2024-01-29 17:08:00,650 [main] INFO  org.apache.pig.newplan.logical.optimizer.LogicalPlanOptimizer - {RULES_ENABLED=[AddForEach, ColumnMapKeyPrune, ConstantCalculator, GroupByConstParallelSetter, LimitOptimizer, LoadTypeCastInserter, MergeFilter, MergeForEach, NestedLimitOptimizer, PartitionFilterOptimizer, PredicatePushdownOptimizer, PushDownForEachFlatten, PushUpFilter, SplitFilter, StreamTypeCastInserter]}\n",
      "2024-01-29 17:08:00,687 [main] INFO  org.apache.pig.impl.util.SpillableMemoryManager - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128\n",
      "2024-01-29 17:08:00,720 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler - File concatenation threshold: 100 optimistic? false\n",
      "2024-01-29 17:08:00,733 [main] INFO  org.apache.pig.backend.hadoop.executionengine.util.CombinerOptimizerUtil - Choosing to move algebraic foreach to combiner\n",
      "2024-01-29 17:08:00,736 [main] INFO  org.apache.pig.backend.hadoop.executionengine.util.CombinerOptimizerUtil - Choosing to move algebraic foreach to combiner\n",
      "2024-01-29 17:08:00,744 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.SecondaryKeyOptimizerMR - Using Secondary Key Optimization for MapReduce node scope-98\n",
      "2024-01-29 17:08:00,746 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler$LastInputStreamingOptimizer - Rewrite: POPackage->POForEach to POPackage(JoinPackager)\n",
      "2024-01-29 17:08:00,751 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer - MR plan size before optimization: 7\n",
      "2024-01-29 17:08:00,752 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer - Merged MR job 85 into MR job 82\n",
      "2024-01-29 17:08:00,752 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer - Merged MR job 90 into MR job 82\n",
      "2024-01-29 17:08:00,752 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer - Requested parallelism of splitter: -1\n",
      "2024-01-29 17:08:00,752 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer - Merged 2 map-reduce splittees.\n",
      "2024-01-29 17:08:00,752 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer - Merged 2 out of total 3 MR operators.\n",
      "2024-01-29 17:08:00,752 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer - MR plan size after optimization: 5\n",
      "2024-01-29 17:08:00,844 [main] INFO  org.apache.hadoop.metrics2.impl.MetricsConfig - Loaded properties from hadoop-metrics2.properties\n",
      "2024-01-29 17:08:00,892 [main] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - Scheduled Metric snapshot period at 10 second(s).\n",
      "2024-01-29 17:08:00,892 [main] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system started\n",
      "2024-01-29 17:08:00,906 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState - Pig script settings are added to the job\n",
      "2024-01-29 17:08:00,909 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.reduce.markreset.buffer.percent is deprecated. Instead, use mapreduce.reduce.markreset.buffer.percent\n",
      "2024-01-29 17:08:00,909 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3\n",
      "2024-01-29 17:08:00,910 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.output.compress is deprecated. Instead, use mapreduce.output.fileoutputformat.compress\n",
      "2024-01-29 17:08:00,911 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Reduce phase detected, estimating # of required reducers.\n",
      "2024-01-29 17:08:00,912 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Using reducer estimator: org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.InputSizeReducerEstimator\n",
      "2024-01-29 17:08:00,919 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.InputSizeReducerEstimator - BytesPerReducer=1000000000 maxReducers=999 totalInputFileSize=72088113\n",
      "2024-01-29 17:08:00,919 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Setting Parallelism to 1\n",
      "2024-01-29 17:08:00,919 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces\n",
      "2024-01-29 17:08:00,926 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Setting up multi store job\n",
      "2024-01-29 17:08:00,941 [main] INFO  org.apache.pig.data.SchemaTupleFrontend - Key [pig.schematuple] is false, will not generate code.\n",
      "2024-01-29 17:08:00,941 [main] INFO  org.apache.pig.data.SchemaTupleFrontend - Starting process to move generated code to distributed cacche\n",
      "2024-01-29 17:08:00,941 [main] INFO  org.apache.pig.data.SchemaTupleFrontend - Distributed cache not supported or needed in local mode. Setting key [pig.schematuple.local.dir] with code temp directory: /tmp/1706544480931-0\n",
      "2024-01-29 17:08:00,996 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 1 map-reduce job(s) waiting for submission.\n",
      "2024-01-29 17:08:01,001 [JobControl] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-01-29 17:08:01,008 [JobControl] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id\n",
      "2024-01-29 17:08:01,037 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
      "2024-01-29 17:08:01,050 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2024-01-29 17:08:01,050 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths to process : 1\n",
      "2024-01-29 17:08:01,059 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths (combined) to process : 3\n",
      "2024-01-29 17:08:01,079 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:3\n",
      "2024-01-29 17:08:01,151 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local533391016_0001\n",
      "2024-01-29 17:08:01,151 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Executing with tokens: []\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-29 17:08:01,229 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/\n",
      "2024-01-29 17:08:01,229 [Thread-6] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null\n",
      "2024-01-29 17:08:01,245 [Thread-6] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces\n",
      "2024-01-29 17:08:01,245 [Thread-6] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address\n",
      "2024-01-29 17:08:01,245 [Thread-6] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.reduce.markreset.buffer.percent is deprecated. Instead, use mapreduce.reduce.markreset.buffer.percent\n",
      "2024-01-29 17:08:01,247 [Thread-6] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-01-29 17:08:01,247 [Thread-6] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-01-29 17:08:01,249 [Thread-6] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-01-29 17:08:01,249 [Thread-6] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-01-29 17:08:01,249 [Thread-6] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigOutputCommitter\n",
      "2024-01-29 17:08:01,277 [Thread-6] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks\n",
      "2024-01-29 17:08:01,278 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local533391016_0001_m_000000_0\n",
      "2024-01-29 17:08:01,302 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-01-29 17:08:01,302 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-01-29 17:08:01,303 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-01-29 17:08:01,303 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-01-29 17:08:01,314 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2024-01-29 17:08:01,318 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Processing split: Number of splits :1\n",
      "Total Length = 33554432\n",
      "Input split[0]:\n",
      "   Length = 33554432\n",
      "   ClassName: org.apache.hadoop.mapreduce.lib.input.FileSplit\n",
      "   Locations:\n",
      "\n",
      "-----------------------\n",
      "\n",
      "2024-01-29 17:08:01,327 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigRecordReader - Current split being processed file:/media/notebooks/flights.csv:0+33554432\n",
      "2024-01-29 17:08:01,358 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)\n",
      "2024-01-29 17:08:01,358 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100\n",
      "2024-01-29 17:08:01,358 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - soft limit at 83886080\n",
      "2024-01-29 17:08:01,358 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600\n",
      "2024-01-29 17:08:01,358 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600\n",
      "2024-01-29 17:08:01,362 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "2024-01-29 17:08:01,379 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.impl.util.SpillableMemoryManager - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128\n",
      "2024-01-29 17:08:01,380 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.data.SchemaTupleBackend - Key [pig.schematuple] was not set... will not generate code.\n",
      "2024-01-29 17:08:01,390 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigGenericMapReduce$Map - Aliases being processed per job phase (AliasName[line,offset]): M: FLIGHTS[11,10],FLIGHTS[-1,-1],vuelos_retrasados[17,20],vuelos_recuperados[20,21],total_recuperados[24,20],contar_recuperados[23,21],total_retrasos[28,17],contar_retrasos[27,18] C: total_recuperados[24,20],contar_recuperados[23,21],total_retrasos[28,17],contar_retrasos[27,18] R: total_recuperados[24,20],total_retrasos[28,17]\n",
      "2024-01-29 17:08:01,579 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - HadoopJobId: job_local533391016_0001\n",
      "2024-01-29 17:08:01,579 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - Processing aliases FLIGHTS,contar_recuperados,contar_retrasos,total_recuperados,total_retrasos,vuelos_recuperados,vuelos_retrasados\n",
      "2024-01-29 17:08:01,579 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - detailed locations: M: FLIGHTS[11,10],FLIGHTS[-1,-1],vuelos_retrasados[17,20],vuelos_recuperados[20,21],total_recuperados[24,20],contar_recuperados[23,21],total_retrasos[28,17],contar_retrasos[27,18] C: total_recuperados[24,20],contar_recuperados[23,21],total_retrasos[28,17],contar_retrasos[27,18] R: total_recuperados[24,20],total_retrasos[28,17]\n",
      "2024-01-29 17:08:01,581 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 0% complete\n",
      "2024-01-29 17:08:01,581 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - Running jobs are [job_local533391016_0001]\n",
      "2024-01-29 17:08:05,490 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - \n",
      "2024-01-29 17:08:05,490 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Starting flush of map output\n",
      "2024-01-29 17:08:05,490 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Spilling map output\n",
      "2024-01-29 17:08:05,490 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 3119320; bufvoid = 104857600\n",
      "2024-01-29 17:08:05,490 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 24966672(99866688); length = 1247725/6553600\n",
      "2024-01-29 17:08:05,563 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigCombiner$Combine - Aliases being processed per job phase (AliasName[line,offset]): M: FLIGHTS[11,10],FLIGHTS[-1,-1],vuelos_retrasados[17,20],vuelos_recuperados[20,21],total_recuperados[24,20],contar_recuperados[23,21],total_retrasos[28,17],contar_retrasos[27,18] C: total_recuperados[24,20],contar_recuperados[23,21],total_retrasos[28,17],contar_retrasos[27,18] R: total_recuperados[24,20],total_retrasos[28,17]\n",
      "2024-01-29 17:08:05,713 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Finished spill 0\n",
      "2024-01-29 17:08:05,721 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local533391016_0001_m_000000_0 is done. And is in the process of committing\n",
      "2024-01-29 17:08:05,722 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - map\n",
      "2024-01-29 17:08:05,722 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local533391016_0001_m_000000_0' done.\n",
      "2024-01-29 17:08:05,726 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local533391016_0001_m_000000_0: Counters: 18\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=33559711\n",
      "\t\tFILE: Number of bytes written=639762\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=1257485\n",
      "\t\tMap output records=311932\n",
      "\t\tMap output bytes=3119320\n",
      "\t\tMap output materialized bytes=455\n",
      "\t\tInput split bytes=360\n",
      "\t\tCombine input records=311932\n",
      "\t\tCombine output records=32\n",
      "\t\tSpilled Records=32\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=95\n",
      "\t\tTotal committed heap usage (bytes)=597164032\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=0\n",
      "2024-01-29 17:08:05,726 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local533391016_0001_m_000000_0\n",
      "2024-01-29 17:08:05,727 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local533391016_0001_m_000001_0\n",
      "2024-01-29 17:08:05,730 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-01-29 17:08:05,730 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-29 17:08:05,732 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-01-29 17:08:05,732 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-01-29 17:08:05,732 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2024-01-29 17:08:05,733 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Processing split: Number of splits :1\n",
      "Total Length = 33554432\n",
      "Input split[0]:\n",
      "   Length = 33554432\n",
      "   ClassName: org.apache.hadoop.mapreduce.lib.input.FileSplit\n",
      "   Locations:\n",
      "\n",
      "-----------------------\n",
      "\n",
      "2024-01-29 17:08:05,736 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigRecordReader - Current split being processed file:/media/notebooks/flights.csv:33554432+33554432\n",
      "2024-01-29 17:08:05,742 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)\n",
      "2024-01-29 17:08:05,742 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100\n",
      "2024-01-29 17:08:05,742 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - soft limit at 83886080\n",
      "2024-01-29 17:08:05,743 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600\n",
      "2024-01-29 17:08:05,743 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600\n",
      "2024-01-29 17:08:05,744 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "2024-01-29 17:08:05,757 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.impl.util.SpillableMemoryManager - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128\n",
      "2024-01-29 17:08:05,758 [LocalJobRunner Map Task Executor #0] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\n",
      "2024-01-29 17:08:05,763 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigGenericMapReduce$Map - Aliases being processed per job phase (AliasName[line,offset]): M: FLIGHTS[11,10],FLIGHTS[-1,-1],vuelos_retrasados[17,20],vuelos_recuperados[20,21],total_recuperados[24,20],contar_recuperados[23,21],total_retrasos[28,17],contar_retrasos[27,18] C: total_recuperados[24,20],contar_recuperados[23,21],total_retrasos[28,17],contar_retrasos[27,18] R: total_recuperados[24,20],total_retrasos[28,17]\n",
      "2024-01-29 17:08:06,082 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 10% complete\n",
      "2024-01-29 17:08:06,083 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - Running jobs are [job_local533391016_0001]\n",
      "2024-01-29 17:08:09,687 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - \n",
      "2024-01-29 17:08:09,687 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Starting flush of map output\n",
      "2024-01-29 17:08:09,687 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Spilling map output\n",
      "2024-01-29 17:08:09,687 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 2854600; bufvoid = 104857600\n",
      "2024-01-29 17:08:09,687 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 25072560(100290240); length = 1141837/6553600\n",
      "2024-01-29 17:08:09,827 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Finished spill 0\n",
      "2024-01-29 17:08:09,828 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local533391016_0001_m_000001_0 is done. And is in the process of committing\n",
      "2024-01-29 17:08:09,829 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - map\n",
      "2024-01-29 17:08:09,829 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local533391016_0001_m_000001_0' done.\n",
      "2024-01-29 17:08:09,830 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local533391016_0001_m_000001_0: Counters: 18\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=67119346\n",
      "\t\tFILE: Number of bytes written=640249\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=1258869\n",
      "\t\tMap output records=285460\n",
      "\t\tMap output bytes=2854600\n",
      "\t\tMap output materialized bytes=455\n",
      "\t\tInput split bytes=360\n",
      "\t\tCombine input records=285460\n",
      "\t\tCombine output records=32\n",
      "\t\tSpilled Records=32\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=219\n",
      "\t\tTotal committed heap usage (bytes)=656932864\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=0\n",
      "2024-01-29 17:08:09,830 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local533391016_0001_m_000001_0\n",
      "2024-01-29 17:08:09,830 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local533391016_0001_m_000002_0\n",
      "2024-01-29 17:08:09,832 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-01-29 17:08:09,832 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-01-29 17:08:09,834 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-01-29 17:08:09,834 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-01-29 17:08:09,834 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2024-01-29 17:08:09,836 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Processing split: Number of splits :1\n",
      "Total Length = 4979249\n",
      "Input split[0]:\n",
      "   Length = 4979249\n",
      "   ClassName: org.apache.hadoop.mapreduce.lib.input.FileSplit\n",
      "   Locations:\n",
      "\n",
      "-----------------------\n",
      "\n",
      "2024-01-29 17:08:09,837 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigRecordReader - Current split being processed file:/media/notebooks/flights.csv:67108864+4979249\n",
      "2024-01-29 17:08:09,842 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)\n",
      "2024-01-29 17:08:09,842 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100\n",
      "2024-01-29 17:08:09,842 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - soft limit at 83886080\n",
      "2024-01-29 17:08:09,842 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600\n",
      "2024-01-29 17:08:09,842 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600\n",
      "2024-01-29 17:08:09,844 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "2024-01-29 17:08:09,854 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.impl.util.SpillableMemoryManager - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128\n",
      "2024-01-29 17:08:09,855 [LocalJobRunner Map Task Executor #0] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\n",
      "2024-01-29 17:08:09,858 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigGenericMapReduce$Map - Aliases being processed per job phase (AliasName[line,offset]): M: FLIGHTS[11,10],FLIGHTS[-1,-1],vuelos_retrasados[17,20],vuelos_recuperados[20,21],total_recuperados[24,20],contar_recuperados[23,21],total_retrasos[28,17],contar_retrasos[27,18] C: total_recuperados[24,20],contar_recuperados[23,21],total_retrasos[28,17],contar_retrasos[27,18] R: total_recuperados[24,20],total_retrasos[28,17]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-29 17:08:10,405 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - \n",
      "2024-01-29 17:08:10,405 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Starting flush of map output\n",
      "2024-01-29 17:08:10,405 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Spilling map output\n",
      "2024-01-29 17:08:10,405 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 288340; bufvoid = 104857600\n",
      "2024-01-29 17:08:10,405 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26099064(104396256); length = 115333/6553600\n",
      "2024-01-29 17:08:10,433 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Finished spill 0\n",
      "2024-01-29 17:08:10,434 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local533391016_0001_m_000002_0 is done. And is in the process of committing\n",
      "2024-01-29 17:08:10,435 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - map\n",
      "2024-01-29 17:08:10,435 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local533391016_0001_m_000002_0' done.\n",
      "2024-01-29 17:08:10,435 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local533391016_0001_m_000002_0: Counters: 18\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=72099190\n",
      "\t\tFILE: Number of bytes written=640620\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=185864\n",
      "\t\tMap output records=28834\n",
      "\t\tMap output bytes=288340\n",
      "\t\tMap output materialized bytes=339\n",
      "\t\tInput split bytes=360\n",
      "\t\tCombine input records=28834\n",
      "\t\tCombine output records=24\n",
      "\t\tSpilled Records=24\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=39\n",
      "\t\tTotal committed heap usage (bytes)=698875904\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=0\n",
      "2024-01-29 17:08:10,436 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local533391016_0001_m_000002_0\n",
      "2024-01-29 17:08:10,436 [Thread-6] INFO  org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.\n",
      "2024-01-29 17:08:10,437 [Thread-6] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks\n",
      "2024-01-29 17:08:10,438 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local533391016_0001_r_000000_0\n",
      "2024-01-29 17:08:10,447 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-01-29 17:08:10,447 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-01-29 17:08:10,448 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-01-29 17:08:10,448 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-01-29 17:08:10,451 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2024-01-29 17:08:10,453 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@33da6fd5\n",
      "2024-01-29 17:08:10,454 [pool-4-thread-1] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-01-29 17:08:10,464 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=652528832, maxSingleShuffleLimit=163132208, mergeThreshold=430669056, ioSortFactor=10, memToMemMergeOutputsThreshold=10\n",
      "2024-01-29 17:08:10,466 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local533391016_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events\n",
      "2024-01-29 17:08:10,482 [localfetcher#1] INFO  org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local533391016_0001_m_000000_0 decomp: 451 len: 455 to MEMORY\n",
      "2024-01-29 17:08:10,484 [localfetcher#1] INFO  org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 451 bytes from map-output for attempt_local533391016_0001_m_000000_0\n",
      "2024-01-29 17:08:10,485 [localfetcher#1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 451, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->451\n",
      "2024-01-29 17:08:10,487 [localfetcher#1] INFO  org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local533391016_0001_m_000001_0 decomp: 451 len: 455 to MEMORY\n",
      "2024-01-29 17:08:10,487 [localfetcher#1] INFO  org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 451 bytes from map-output for attempt_local533391016_0001_m_000001_0\n",
      "2024-01-29 17:08:10,487 [localfetcher#1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 451, inMemoryMapOutputs.size() -> 2, commitMemory -> 451, usedMemory ->902\n",
      "2024-01-29 17:08:10,488 [localfetcher#1] INFO  org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local533391016_0001_m_000002_0 decomp: 335 len: 339 to MEMORY\n",
      "2024-01-29 17:08:10,488 [localfetcher#1] INFO  org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 335 bytes from map-output for attempt_local533391016_0001_m_000002_0\n",
      "2024-01-29 17:08:10,488 [localfetcher#1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 335, inMemoryMapOutputs.size() -> 3, commitMemory -> 902, usedMemory ->1237\n",
      "2024-01-29 17:08:10,489 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning\n",
      "2024-01-29 17:08:10,489 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 3 / 3 copied.\n",
      "2024-01-29 17:08:10,489 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs\n",
      "2024-01-29 17:08:10,495 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 3 sorted segments\n",
      "2024-01-29 17:08:10,495 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 3 segments left of total size: 1216 bytes\n",
      "2024-01-29 17:08:10,496 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 3 segments, 1237 bytes to disk to satisfy reduce memory limit\n",
      "2024-01-29 17:08:10,496 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 1237 bytes from disk\n",
      "2024-01-29 17:08:10,497 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce\n",
      "2024-01-29 17:08:10,497 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 1 sorted segments\n",
      "2024-01-29 17:08:10,497 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 1226 bytes\n",
      "2024-01-29 17:08:10,497 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 3 / 3 copied.\n",
      "2024-01-29 17:08:10,499 [pool-4-thread-1] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords\n",
      "2024-01-29 17:08:10,500 [pool-4-thread-1] INFO  org.apache.pig.impl.util.SpillableMemoryManager - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128\n",
      "2024-01-29 17:08:10,500 [pool-4-thread-1] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\n",
      "2024-01-29 17:08:10,502 [pool-4-thread-1] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigMapReduce$Reduce - Aliases being processed per job phase (AliasName[line,offset]): M: FLIGHTS[11,10],FLIGHTS[-1,-1],vuelos_retrasados[17,20],vuelos_recuperados[20,21],total_recuperados[24,20],contar_recuperados[23,21],total_retrasos[28,17],contar_retrasos[27,18] C: total_recuperados[24,20],contar_recuperados[23,21],total_retrasos[28,17],contar_retrasos[27,18] R: total_recuperados[24,20],total_retrasos[28,17]\n",
      "2024-01-29 17:08:10,504 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-01-29 17:08:10,504 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-01-29 17:08:10,507 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-01-29 17:08:10,507 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-29 17:08:10,512 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local533391016_0001_r_000000_0 is done. And is in the process of committing\n",
      "2024-01-29 17:08:10,516 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 3 / 3 copied.\n",
      "2024-01-29 17:08:10,516 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task - Task attempt_local533391016_0001_r_000000_0 is allowed to commit now\n",
      "2024-01-29 17:08:10,518 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local533391016_0001_r_000000_0' to file:/tmp/temp-679547720/tmp-1207363180\n",
      "2024-01-29 17:08:10,520 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local533391016_0001_r_000000_0' to file:/tmp/temp-679547720/tmp-1789324695\n",
      "2024-01-29 17:08:10,521 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce\n",
      "2024-01-29 17:08:10,521 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local533391016_0001_r_000000_0' done.\n",
      "2024-01-29 17:08:10,521 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local533391016_0001_r_000000_0: Counters: 24\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=72101772\n",
      "\t\tFILE: Number of bytes written=642277\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=32\n",
      "\t\tReduce shuffle bytes=1249\n",
      "\t\tReduce input records=88\n",
      "\t\tReduce output records=0\n",
      "\t\tSpilled Records=88\n",
      "\t\tShuffled Maps =3\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=3\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=698875904\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=0\n",
      "2024-01-29 17:08:10,521 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local533391016_0001_r_000000_0\n",
      "2024-01-29 17:08:10,521 [Thread-6] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.\n",
      "2024-01-29 17:08:10,584 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 20% complete\n",
      "2024-01-29 17:08:10,586 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-01-29 17:08:10,594 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-01-29 17:08:10,595 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps\n",
      "2024-01-29 17:08:10,596 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-01-29 17:08:10,608 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState - Pig script settings are added to the job\n",
      "2024-01-29 17:08:10,609 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3\n",
      "2024-01-29 17:08:10,609 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Reduce phase detected, estimating # of required reducers.\n",
      "2024-01-29 17:08:10,609 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Using reducer estimator: org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.InputSizeReducerEstimator\n",
      "2024-01-29 17:08:10,610 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.InputSizeReducerEstimator - BytesPerReducer=1000000000 maxReducers=999 totalInputFileSize=396\n",
      "2024-01-29 17:08:10,610 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Setting Parallelism to 1\n",
      "2024-01-29 17:08:10,612 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Setting up single store job\n",
      "2024-01-29 17:08:10,624 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 1 map-reduce job(s) waiting for submission.\n",
      "2024-01-29 17:08:10,626 [JobControl] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-01-29 17:08:10,630 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
      "2024-01-29 17:08:10,634 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2024-01-29 17:08:10,634 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths to process : 1\n",
      "2024-01-29 17:08:10,634 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths (combined) to process : 1\n",
      "2024-01-29 17:08:10,636 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2024-01-29 17:08:10,636 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths to process : 1\n",
      "2024-01-29 17:08:10,636 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths (combined) to process : 1\n",
      "2024-01-29 17:08:10,637 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:2\n",
      "2024-01-29 17:08:10,644 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local346672689_0002\n",
      "2024-01-29 17:08:10,644 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Executing with tokens: []\n",
      "2024-01-29 17:08:10,688 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/\n",
      "2024-01-29 17:08:10,689 [Thread-17] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null\n",
      "2024-01-29 17:08:10,693 [Thread-17] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces\n",
      "2024-01-29 17:08:10,693 [Thread-17] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address\n",
      "2024-01-29 17:08:10,693 [Thread-17] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.reduce.markreset.buffer.percent is deprecated. Instead, use mapreduce.reduce.markreset.buffer.percent\n",
      "2024-01-29 17:08:10,693 [Thread-17] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-01-29 17:08:10,693 [Thread-17] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-01-29 17:08:10,693 [Thread-17] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigOutputCommitter\n",
      "2024-01-29 17:08:10,697 [Thread-17] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks\n",
      "2024-01-29 17:08:10,697 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local346672689_0002_m_000000_0\n",
      "2024-01-29 17:08:10,702 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-01-29 17:08:10,702 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-01-29 17:08:10,702 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2024-01-29 17:08:10,703 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Processing split: Number of splits :1\n",
      "Total Length = 202\n",
      "Input split[0]:\n",
      "   Length = 202\n",
      "   ClassName: org.apache.hadoop.mapreduce.lib.input.FileSplit\n",
      "   Locations:\n",
      "\n",
      "-----------------------\n",
      "\n",
      "2024-01-29 17:08:10,707 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigRecordReader - Current split being processed file:/tmp/temp-679547720/tmp-1789324695/part-r-00000:0+202\n",
      "2024-01-29 17:08:10,713 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)\n",
      "2024-01-29 17:08:10,714 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-29 17:08:10,714 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - soft limit at 83886080\r\n",
      "2024-01-29 17:08:10,714 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600\r\n",
      "2024-01-29 17:08:10,714 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600\r\n",
      "2024-01-29 17:08:10,715 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "2024-01-29 17:08:10,719 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.impl.util.SpillableMemoryManager - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128\r\n",
      "2024-01-29 17:08:10,719 [LocalJobRunner Map Task Executor #0] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\r\n",
      "2024-01-29 17:08:10,720 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigGenericMapReduce$Map - Aliases being processed per job phase (AliasName[line,offset]): M: recover[31,10],recover[31,10] C:  R: recover[32,10]\r\n",
      "2024-01-29 17:08:10,721 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - \r\n",
      "2024-01-29 17:08:10,721 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Starting flush of map output\r\n",
      "2024-01-29 17:08:10,721 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Spilling map output\r\n",
      "2024-01-29 17:08:10,721 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 186; bufvoid = 104857600\r\n",
      "2024-01-29 17:08:10,721 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214336(104857344); length = 61/6553600\r\n",
      "2024-01-29 17:08:10,724 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Finished spill 0\r\n",
      "2024-01-29 17:08:10,725 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local346672689_0002_m_000000_0 is done. And is in the process of committing\r\n",
      "2024-01-29 17:08:10,726 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - map\r\n",
      "2024-01-29 17:08:10,726 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local346672689_0002_m_000000_0' done.\r\n",
      "2024-01-29 17:08:10,726 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local346672689_0002_m_000000_0: Counters: 18\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=72102823\r\n",
      "\t\tFILE: Number of bytes written=1255233\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=16\r\n",
      "\t\tMap output records=16\r\n",
      "\t\tMap output bytes=186\r\n",
      "\t\tMap output materialized bytes=224\r\n",
      "\t\tInput split bytes=379\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=16\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=4\r\n",
      "\t\tTotal committed heap usage (bytes)=698351616\r\n",
      "\tMultiInputCounters\r\n",
      "\t\tInput records from _1_tmp-1789324695=16\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=0\r\n",
      "2024-01-29 17:08:10,726 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local346672689_0002_m_000000_0\r\n",
      "2024-01-29 17:08:10,726 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local346672689_0002_m_000001_0\r\n",
      "2024-01-29 17:08:10,729 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\r\n",
      "2024-01-29 17:08:10,729 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "2024-01-29 17:08:10,730 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "2024-01-29 17:08:10,730 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Processing split: Number of splits :1\r\n",
      "Total Length = 194\r\n",
      "Input split[0]:\r\n",
      "   Length = 194\r\n",
      "   ClassName: org.apache.hadoop.mapreduce.lib.input.FileSplit\r\n",
      "   Locations:\r\n",
      "\r\n",
      "-----------------------\r\n",
      "\r\n",
      "2024-01-29 17:08:10,732 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigRecordReader - Current split being processed file:/tmp/temp-679547720/tmp-1207363180/part-r-00000:0+194\r\n",
      "2024-01-29 17:08:10,735 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)\r\n",
      "2024-01-29 17:08:10,735 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100\r\n",
      "2024-01-29 17:08:10,735 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - soft limit at 83886080\r\n",
      "2024-01-29 17:08:10,735 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600\r\n",
      "2024-01-29 17:08:10,735 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600\r\n",
      "2024-01-29 17:08:10,735 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\r\n",
      "2024-01-29 17:08:10,737 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.impl.util.SpillableMemoryManager - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128\r\n",
      "2024-01-29 17:08:10,737 [LocalJobRunner Map Task Executor #0] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\r\n",
      "2024-01-29 17:08:10,737 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigGenericMapReduce$Map - Aliases being processed per job phase (AliasName[line,offset]): M: recover[31,10],recover[31,10] C:  R: recover[32,10]\r\n",
      "2024-01-29 17:08:10,738 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - \r\n",
      "2024-01-29 17:08:10,738 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Starting flush of map output\r\n",
      "2024-01-29 17:08:10,738 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Spilling map output\r\n",
      "2024-01-29 17:08:10,738 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 178; bufvoid = 104857600\r\n",
      "2024-01-29 17:08:10,738 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214336(104857344); length = 61/6553600\r\n",
      "2024-01-29 17:08:10,740 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Finished spill 0\r\n",
      "2024-01-29 17:08:10,741 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local346672689_0002_m_000001_0 is done. And is in the process of committing\r\n",
      "2024-01-29 17:08:10,741 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - map\r\n",
      "2024-01-29 17:08:10,741 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local346672689_0002_m_000001_0' done.\r\n",
      "2024-01-29 17:08:10,742 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local346672689_0002_m_000001_0: Counters: 18\r\n",
      "\tFile System Counters\r\n",
      "\t\tFILE: Number of bytes read=72103814\r\n",
      "\t\tFILE: Number of bytes written=1255481\r\n",
      "\t\tFILE: Number of read operations=0\r\n",
      "\t\tFILE: Number of large read operations=0\r\n",
      "\t\tFILE: Number of write operations=0\r\n",
      "\tMap-Reduce Framework\r\n",
      "\t\tMap input records=16\r\n",
      "\t\tMap output records=16\r\n",
      "\t\tMap output bytes=178\r\n",
      "\t\tMap output materialized bytes=216\r\n",
      "\t\tInput split bytes=379\r\n",
      "\t\tCombine input records=0\r\n",
      "\t\tSpilled Records=16\r\n",
      "\t\tFailed Shuffles=0\r\n",
      "\t\tMerged Map outputs=0\r\n",
      "\t\tGC time elapsed (ms)=0\r\n",
      "\t\tTotal committed heap usage (bytes)=698351616\r\n",
      "\tMultiInputCounters\r\n",
      "\t\tInput records from _0_tmp-1207363180=16\r\n",
      "\tFile Input Format Counters \r\n",
      "\t\tBytes Read=0\r\n",
      "2024-01-29 17:08:10,742 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local346672689_0002_m_000001_0\r\n",
      "2024-01-29 17:08:10,742 [Thread-17] INFO  org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.\r\n",
      "2024-01-29 17:08:10,742 [Thread-17] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks\r\n",
      "2024-01-29 17:08:10,743 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local346672689_0002_r_000000_0\r\n",
      "2024-01-29 17:08:10,748 [pool-9-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\r\n",
      "2024-01-29 17:08:10,748 [pool-9-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "2024-01-29 17:08:10,749 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\r\n",
      "2024-01-29 17:08:10,749 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@6808552f\r\n",
      "2024-01-29 17:08:10,749 [pool-9-thread-1] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\r\n",
      "2024-01-29 17:08:10,750 [pool-9-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=652528832, maxSingleShuffleLimit=163132208, mergeThreshold=430669056, ioSortFactor=10, memToMemMergeOutputsThreshold=10\r\n",
      "2024-01-29 17:08:10,751 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local346672689_0002_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events\r\n",
      "2024-01-29 17:08:10,751 [localfetcher#2] INFO  org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#2 about to shuffle output of map attempt_local346672689_0002_m_000001_0 decomp: 212 len: 216 to MEMORY\r\n",
      "2024-01-29 17:08:10,752 [localfetcher#2] INFO  org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 212 bytes from map-output for attempt_local346672689_0002_m_000001_0\r\n",
      "2024-01-29 17:08:10,752 [localfetcher#2] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 212, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->212\r\n",
      "2024-01-29 17:08:10,753 [localfetcher#2] INFO  org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#2 about to shuffle output of map attempt_local346672689_0002_m_000000_0 decomp: 220 len: 224 to MEMORY\r\n",
      "2024-01-29 17:08:10,753 [localfetcher#2] INFO  org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 220 bytes from map-output for attempt_local346672689_0002_m_000000_0\r\n",
      "2024-01-29 17:08:10,753 [localfetcher#2] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 220, inMemoryMapOutputs.size() -> 2, commitMemory -> 212, usedMemory ->432\r\n",
      "2024-01-29 17:08:10,753 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning\r\n",
      "2024-01-29 17:08:10,753 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 2 / 2 copied.\r\n",
      "2024-01-29 17:08:10,754 [pool-9-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 2 in-memory map-outputs and 0 on-disk map-outputs\r\n",
      "2024-01-29 17:08:10,755 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 2 sorted segments\r\n",
      "2024-01-29 17:08:10,755 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 2 segments left of total size: 418 bytes\r\n",
      "2024-01-29 17:08:10,756 [pool-9-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 2 segments, 432 bytes to disk to satisfy reduce memory limit\r\n",
      "2024-01-29 17:08:10,756 [pool-9-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 434 bytes from disk\r\n",
      "2024-01-29 17:08:10,756 [pool-9-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce\r\n",
      "2024-01-29 17:08:10,756 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 1 sorted segments\r\n",
      "2024-01-29 17:08:10,756 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 423 bytes\r\n",
      "2024-01-29 17:08:10,757 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 2 / 2 copied.\r\n",
      "2024-01-29 17:08:10,759 [pool-9-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\r\n",
      "2024-01-29 17:08:10,759 [pool-9-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\r\n",
      "2024-01-29 17:08:10,761 [pool-9-thread-1] INFO  org.apache.pig.impl.util.SpillableMemoryManager - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128\r\n",
      "2024-01-29 17:08:10,761 [pool-9-thread-1] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\r\n",
      "2024-01-29 17:08:10,763 [pool-9-thread-1] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigMapReduce$Reduce - Aliases being processed per job phase (AliasName[line,offset]): M: recover[31,10],recover[31,10] C:  R: recover[32,10]\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-29 17:08:10,768 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local346672689_0002_r_000000_0 is done. And is in the process of committing\n",
      "2024-01-29 17:08:10,770 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 2 / 2 copied.\n",
      "2024-01-29 17:08:10,770 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.Task - Task attempt_local346672689_0002_r_000000_0 is allowed to commit now\n",
      "2024-01-29 17:08:10,771 [pool-9-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local346672689_0002_r_000000_0' to file:/tmp/temp-679547720/tmp1519621592\n",
      "2024-01-29 17:08:10,771 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce\n",
      "2024-01-29 17:08:10,772 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local346672689_0002_r_000000_0' done.\n",
      "2024-01-29 17:08:10,772 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local346672689_0002_r_000000_0: Counters: 24\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=72104752\n",
      "\t\tFILE: Number of bytes written=1256215\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=16\n",
      "\t\tReduce shuffle bytes=440\n",
      "\t\tReduce input records=32\n",
      "\t\tReduce output records=16\n",
      "\t\tSpilled Records=32\n",
      "\t\tShuffled Maps =2\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=2\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=698351616\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=0\n",
      "2024-01-29 17:08:10,772 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local346672689_0002_r_000000_0\n",
      "2024-01-29 17:08:10,772 [Thread-17] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.\n",
      "2024-01-29 17:08:10,889 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - HadoopJobId: job_local346672689_0002\n",
      "2024-01-29 17:08:10,889 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - Processing aliases recover\n",
      "2024-01-29 17:08:10,889 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - detailed locations: M: recover[31,10],recover[31,10] C:  R: recover[32,10]\n",
      "2024-01-29 17:08:10,890 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 40% complete\n",
      "2024-01-29 17:08:10,891 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-01-29 17:08:10,892 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-01-29 17:08:10,893 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-01-29 17:08:10,898 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState - Pig script settings are added to the job\n",
      "2024-01-29 17:08:10,899 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3\n",
      "2024-01-29 17:08:10,899 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Reduce phase detected, estimating # of required reducers.\n",
      "2024-01-29 17:08:10,899 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Using reducer estimator: org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.InputSizeReducerEstimator\n",
      "2024-01-29 17:08:10,900 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.InputSizeReducerEstimator - BytesPerReducer=1000000000 maxReducers=999 totalInputFileSize=288\n",
      "2024-01-29 17:08:10,901 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Setting Parallelism to 1\n",
      "2024-01-29 17:08:10,902 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Setting up single store job\n",
      "2024-01-29 17:08:10,914 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 1 map-reduce job(s) waiting for submission.\n",
      "2024-01-29 17:08:10,916 [JobControl] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-01-29 17:08:10,920 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
      "2024-01-29 17:08:10,921 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2024-01-29 17:08:10,921 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths to process : 1\n",
      "2024-01-29 17:08:10,921 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths (combined) to process : 1\n",
      "2024-01-29 17:08:10,922 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1\n",
      "2024-01-29 17:08:10,935 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1232131069_0003\n",
      "2024-01-29 17:08:10,935 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Executing with tokens: []\n",
      "2024-01-29 17:08:10,979 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/\n",
      "2024-01-29 17:08:10,979 [Thread-25] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null\n",
      "2024-01-29 17:08:10,983 [Thread-25] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces\n",
      "2024-01-29 17:08:10,983 [Thread-25] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address\n",
      "2024-01-29 17:08:10,983 [Thread-25] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.reduce.markreset.buffer.percent is deprecated. Instead, use mapreduce.reduce.markreset.buffer.percent\n",
      "2024-01-29 17:08:10,983 [Thread-25] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-01-29 17:08:10,983 [Thread-25] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-01-29 17:08:10,983 [Thread-25] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigOutputCommitter\n",
      "2024-01-29 17:08:10,987 [Thread-25] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks\n",
      "2024-01-29 17:08:10,987 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1232131069_0003_m_000000_0\n",
      "2024-01-29 17:08:10,992 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-01-29 17:08:10,992 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-01-29 17:08:10,992 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2024-01-29 17:08:10,993 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Processing split: Number of splits :1\n",
      "Total Length = 288\n",
      "Input split[0]:\n",
      "   Length = 288\n",
      "   ClassName: org.apache.hadoop.mapreduce.lib.input.FileSplit\n",
      "   Locations:\n",
      "\n",
      "-----------------------\n",
      "\n",
      "2024-01-29 17:08:10,994 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigRecordReader - Current split being processed file:/tmp/temp-679547720/tmp1519621592/part-r-00000:0+288\n",
      "2024-01-29 17:08:11,002 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)\n",
      "2024-01-29 17:08:11,002 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100\n",
      "2024-01-29 17:08:11,002 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - soft limit at 83886080\n",
      "2024-01-29 17:08:11,002 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600\n",
      "2024-01-29 17:08:11,002 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600\n",
      "2024-01-29 17:08:11,006 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "2024-01-29 17:08:11,007 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.impl.util.SpillableMemoryManager - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128\n",
      "2024-01-29 17:08:11,007 [LocalJobRunner Map Task Executor #0] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\n",
      "2024-01-29 17:08:11,008 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigGenericMapReduce$Map - Aliases being processed per job phase (AliasName[line,offset]): M: top5[37,7] C:  R: \n",
      "2024-01-29 17:08:11,009 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - \n",
      "2024-01-29 17:08:11,009 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Starting flush of map output\n",
      "2024-01-29 17:08:11,009 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Spilling map output\n",
      "2024-01-29 17:08:11,009 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 480; bufvoid = 104857600\n",
      "2024-01-29 17:08:11,009 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214336(104857344); length = 61/6553600\n",
      "2024-01-29 17:08:11,016 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Finished spill 0\n",
      "2024-01-29 17:08:11,017 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local1232131069_0003_m_000000_0 is done. And is in the process of committing\n",
      "2024-01-29 17:08:11,017 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - map\n",
      "2024-01-29 17:08:11,017 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local1232131069_0003_m_000000_0' done.\n",
      "2024-01-29 17:08:11,017 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local1232131069_0003_m_000000_0: Counters: 17\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=72105490\n",
      "\t\tFILE: Number of bytes written=1872218\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=16\n",
      "\t\tMap output records=16\n",
      "\t\tMap output bytes=480\n",
      "\t\tMap output materialized bytes=518\n",
      "\t\tInput split bytes=378\n",
      "\t\tCombine input records=0\n",
      "\t\tSpilled Records=16\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=4\n",
      "\t\tTotal committed heap usage (bytes)=697827328\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=0\n",
      "2024-01-29 17:08:11,018 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1232131069_0003_m_000000_0\n",
      "2024-01-29 17:08:11,018 [Thread-25] INFO  org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.\n",
      "2024-01-29 17:08:11,018 [Thread-25] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks\n",
      "2024-01-29 17:08:11,018 [pool-12-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1232131069_0003_r_000000_0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-29 17:08:11,023 [pool-12-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-01-29 17:08:11,023 [pool-12-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-01-29 17:08:11,025 [pool-12-thread-1] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2024-01-29 17:08:11,025 [pool-12-thread-1] INFO  org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@428312a\n",
      "2024-01-29 17:08:11,025 [pool-12-thread-1] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-01-29 17:08:11,026 [pool-12-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=652528832, maxSingleShuffleLimit=163132208, mergeThreshold=430669056, ioSortFactor=10, memToMemMergeOutputsThreshold=10\n",
      "2024-01-29 17:08:11,026 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1232131069_0003_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events\n",
      "2024-01-29 17:08:11,027 [localfetcher#3] INFO  org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#3 about to shuffle output of map attempt_local1232131069_0003_m_000000_0 decomp: 514 len: 518 to MEMORY\n",
      "2024-01-29 17:08:11,027 [localfetcher#3] INFO  org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 514 bytes from map-output for attempt_local1232131069_0003_m_000000_0\n",
      "2024-01-29 17:08:11,027 [localfetcher#3] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 514, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->514\n",
      "2024-01-29 17:08:11,028 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning\n",
      "2024-01-29 17:08:11,028 [pool-12-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2024-01-29 17:08:11,028 [pool-12-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs\n",
      "2024-01-29 17:08:11,030 [pool-12-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 1 sorted segments\n",
      "2024-01-29 17:08:11,030 [pool-12-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 494 bytes\n",
      "2024-01-29 17:08:11,031 [pool-12-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 514 bytes to disk to satisfy reduce memory limit\n",
      "2024-01-29 17:08:11,031 [pool-12-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 518 bytes from disk\n",
      "2024-01-29 17:08:11,031 [pool-12-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce\n",
      "2024-01-29 17:08:11,031 [pool-12-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 1 sorted segments\n",
      "2024-01-29 17:08:11,031 [pool-12-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 494 bytes\n",
      "2024-01-29 17:08:11,031 [pool-12-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2024-01-29 17:08:11,033 [pool-12-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-01-29 17:08:11,033 [pool-12-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-01-29 17:08:11,034 [pool-12-thread-1] INFO  org.apache.pig.impl.util.SpillableMemoryManager - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128\n",
      "2024-01-29 17:08:11,035 [pool-12-thread-1] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\n",
      "2024-01-29 17:08:11,036 [pool-12-thread-1] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigMapReduce$Reduce - Aliases being processed per job phase (AliasName[line,offset]): M: top5[37,7] C:  R: \n",
      "2024-01-29 17:08:11,038 [pool-12-thread-1] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local1232131069_0003_r_000000_0 is done. And is in the process of committing\n",
      "2024-01-29 17:08:11,039 [pool-12-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2024-01-29 17:08:11,039 [pool-12-thread-1] INFO  org.apache.hadoop.mapred.Task - Task attempt_local1232131069_0003_r_000000_0 is allowed to commit now\n",
      "2024-01-29 17:08:11,040 [pool-12-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1232131069_0003_r_000000_0' to file:/tmp/temp-679547720/tmp1068853646\n",
      "2024-01-29 17:08:11,041 [pool-12-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce\n",
      "2024-01-29 17:08:11,041 [pool-12-thread-1] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local1232131069_0003_r_000000_0' done.\n",
      "2024-01-29 17:08:11,041 [pool-12-thread-1] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local1232131069_0003_r_000000_0: Counters: 24\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=72106558\n",
      "\t\tFILE: Number of bytes written=1872805\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=1\n",
      "\t\tReduce shuffle bytes=518\n",
      "\t\tReduce input records=16\n",
      "\t\tReduce output records=1\n",
      "\t\tSpilled Records=16\n",
      "\t\tShuffled Maps =1\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=1\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=697827328\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=0\n",
      "2024-01-29 17:08:11,041 [pool-12-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1232131069_0003_r_000000_0\n",
      "2024-01-29 17:08:11,041 [Thread-25] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.\n",
      "2024-01-29 17:08:11,179 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - HadoopJobId: job_local1232131069_0003\n",
      "2024-01-29 17:08:11,180 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - Processing aliases top5\n",
      "2024-01-29 17:08:11,180 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - detailed locations: M: top5[37,7] C:  R: \n",
      "2024-01-29 17:08:11,180 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 60% complete\n",
      "2024-01-29 17:08:11,181 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-01-29 17:08:11,183 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-01-29 17:08:11,184 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-01-29 17:08:11,187 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState - Pig script settings are added to the job\n",
      "2024-01-29 17:08:11,187 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3\n",
      "2024-01-29 17:08:11,187 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Reduce phase detected, estimating # of required reducers.\n",
      "2024-01-29 17:08:11,187 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Setting Parallelism to 1\n",
      "2024-01-29 17:08:11,188 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Setting up single store job\n",
      "2024-01-29 17:08:11,200 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 1 map-reduce job(s) waiting for submission.\n",
      "2024-01-29 17:08:11,201 [JobControl] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-01-29 17:08:11,205 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
      "2024-01-29 17:08:11,207 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2024-01-29 17:08:11,207 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths to process : 1\n",
      "2024-01-29 17:08:11,207 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths (combined) to process : 1\n",
      "2024-01-29 17:08:11,208 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1\n",
      "2024-01-29 17:08:11,213 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local856459684_0004\n",
      "2024-01-29 17:08:11,213 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Executing with tokens: []\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-29 17:08:11,252 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/\n",
      "2024-01-29 17:08:11,252 [Thread-32] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null\n",
      "2024-01-29 17:08:11,256 [Thread-32] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces\n",
      "2024-01-29 17:08:11,256 [Thread-32] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address\n",
      "2024-01-29 17:08:11,256 [Thread-32] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.reduce.markreset.buffer.percent is deprecated. Instead, use mapreduce.reduce.markreset.buffer.percent\n",
      "2024-01-29 17:08:11,256 [Thread-32] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-01-29 17:08:11,256 [Thread-32] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-01-29 17:08:11,256 [Thread-32] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigOutputCommitter\n",
      "2024-01-29 17:08:11,260 [Thread-32] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks\n",
      "2024-01-29 17:08:11,260 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local856459684_0004_m_000000_0\n",
      "2024-01-29 17:08:11,265 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-01-29 17:08:11,265 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-01-29 17:08:11,265 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2024-01-29 17:08:11,266 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Processing split: Number of splits :1\n",
      "Total Length = 288\n",
      "Input split[0]:\n",
      "   Length = 288\n",
      "   ClassName: org.apache.hadoop.mapreduce.lib.input.FileSplit\n",
      "   Locations:\n",
      "\n",
      "-----------------------\n",
      "\n",
      "2024-01-29 17:08:11,267 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigRecordReader - Current split being processed file:/tmp/temp-679547720/tmp1519621592/part-r-00000:0+288\n",
      "2024-01-29 17:08:11,270 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)\n",
      "2024-01-29 17:08:11,270 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100\n",
      "2024-01-29 17:08:11,270 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - soft limit at 83886080\n",
      "2024-01-29 17:08:11,270 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600\n",
      "2024-01-29 17:08:11,270 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600\n",
      "2024-01-29 17:08:11,271 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "2024-01-29 17:08:11,272 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.impl.util.SpillableMemoryManager - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128\n",
      "2024-01-29 17:08:11,272 [LocalJobRunner Map Task Executor #0] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\n",
      "2024-01-29 17:08:11,272 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigGenericMapReduce$Map - Aliases being processed per job phase (AliasName[line,offset]): M: top5[37,7] C:  R: \n",
      "2024-01-29 17:08:11,273 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - \n",
      "2024-01-29 17:08:11,273 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Starting flush of map output\n",
      "2024-01-29 17:08:11,273 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Spilling map output\n",
      "2024-01-29 17:08:11,273 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 288; bufvoid = 104857600\n",
      "2024-01-29 17:08:11,273 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214336(104857344); length = 61/6553600\n",
      "2024-01-29 17:08:11,279 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Finished spill 0\n",
      "2024-01-29 17:08:11,280 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local856459684_0004_m_000000_0 is done. And is in the process of committing\n",
      "2024-01-29 17:08:11,281 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - map\n",
      "2024-01-29 17:08:11,281 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local856459684_0004_m_000000_0' done.\n",
      "2024-01-29 17:08:11,281 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local856459684_0004_m_000000_0: Counters: 18\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=72107296\n",
      "\t\tFILE: Number of bytes written=2492825\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=16\n",
      "\t\tMap output records=16\n",
      "\t\tMap output bytes=288\n",
      "\t\tMap output materialized bytes=106\n",
      "\t\tInput split bytes=378\n",
      "\t\tCombine input records=16\n",
      "\t\tCombine output records=5\n",
      "\t\tSpilled Records=5\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=697827328\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=0\n",
      "2024-01-29 17:08:11,281 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local856459684_0004_m_000000_0\n",
      "2024-01-29 17:08:11,281 [Thread-32] INFO  org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.\n",
      "2024-01-29 17:08:11,282 [Thread-32] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks\n",
      "2024-01-29 17:08:11,282 [pool-15-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local856459684_0004_r_000000_0\n",
      "2024-01-29 17:08:11,288 [pool-15-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-01-29 17:08:11,288 [pool-15-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-01-29 17:08:11,289 [pool-15-thread-1] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2024-01-29 17:08:11,289 [pool-15-thread-1] INFO  org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@19d1f0fa\n",
      "2024-01-29 17:08:11,289 [pool-15-thread-1] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-01-29 17:08:11,289 [pool-15-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=652528832, maxSingleShuffleLimit=163132208, mergeThreshold=430669056, ioSortFactor=10, memToMemMergeOutputsThreshold=10\n",
      "2024-01-29 17:08:11,291 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local856459684_0004_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events\n",
      "2024-01-29 17:08:11,291 [localfetcher#4] INFO  org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#4 about to shuffle output of map attempt_local856459684_0004_m_000000_0 decomp: 102 len: 106 to MEMORY\n",
      "2024-01-29 17:08:11,291 [localfetcher#4] INFO  org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 102 bytes from map-output for attempt_local856459684_0004_m_000000_0\n",
      "2024-01-29 17:08:11,292 [localfetcher#4] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 102, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->102\n",
      "2024-01-29 17:08:11,292 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning\n",
      "2024-01-29 17:08:11,292 [pool-15-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2024-01-29 17:08:11,292 [pool-15-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs\n",
      "2024-01-29 17:08:11,294 [pool-15-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 1 sorted segments\n",
      "2024-01-29 17:08:11,294 [pool-15-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 90 bytes\n",
      "2024-01-29 17:08:11,294 [pool-15-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 102 bytes to disk to satisfy reduce memory limit\n",
      "2024-01-29 17:08:11,294 [pool-15-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 106 bytes from disk\n",
      "2024-01-29 17:08:11,294 [pool-15-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce\n",
      "2024-01-29 17:08:11,295 [pool-15-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 1 sorted segments\n",
      "2024-01-29 17:08:11,295 [pool-15-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 90 bytes\n",
      "2024-01-29 17:08:11,295 [pool-15-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2024-01-29 17:08:11,296 [pool-15-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-01-29 17:08:11,296 [pool-15-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-01-29 17:08:11,297 [pool-15-thread-1] INFO  org.apache.pig.impl.util.SpillableMemoryManager - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128\n",
      "2024-01-29 17:08:11,297 [pool-15-thread-1] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\n",
      "2024-01-29 17:08:11,298 [pool-15-thread-1] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigMapReduce$Reduce - Aliases being processed per job phase (AliasName[line,offset]): M: top5[37,7] C:  R: \n",
      "2024-01-29 17:08:11,299 [pool-15-thread-1] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local856459684_0004_r_000000_0 is done. And is in the process of committing\n",
      "2024-01-29 17:08:11,300 [pool-15-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2024-01-29 17:08:11,300 [pool-15-thread-1] INFO  org.apache.hadoop.mapred.Task - Task attempt_local856459684_0004_r_000000_0 is allowed to commit now\n",
      "2024-01-29 17:08:11,301 [pool-15-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local856459684_0004_r_000000_0' to file:/tmp/temp-679547720/tmp-242619885\n",
      "2024-01-29 17:08:11,302 [pool-15-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce\n",
      "2024-01-29 17:08:11,302 [pool-15-thread-1] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local856459684_0004_r_000000_0' done.\n",
      "2024-01-29 17:08:11,302 [pool-15-thread-1] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local856459684_0004_r_000000_0: Counters: 24\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=72107540\n",
      "\t\tFILE: Number of bytes written=2493033\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=5\n",
      "\t\tReduce shuffle bytes=106\n",
      "\t\tReduce input records=5\n",
      "\t\tReduce output records=5\n",
      "\t\tSpilled Records=5\n",
      "\t\tShuffled Maps =1\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=1\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=697827328\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=0\n",
      "2024-01-29 17:08:11,302 [pool-15-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local856459684_0004_r_000000_0\n",
      "2024-01-29 17:08:11,302 [Thread-32] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-29 17:08:11,453 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - HadoopJobId: job_local856459684_0004\n",
      "2024-01-29 17:08:11,453 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - Processing aliases top5\n",
      "2024-01-29 17:08:11,453 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - detailed locations: M: top5[37,7] C:  R: \n",
      "2024-01-29 17:08:11,454 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 80% complete\n",
      "2024-01-29 17:08:11,455 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-01-29 17:08:11,456 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-01-29 17:08:11,457 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-01-29 17:08:11,460 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState - Pig script settings are added to the job\n",
      "2024-01-29 17:08:11,460 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3\n",
      "2024-01-29 17:08:11,461 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Reduce phase detected, estimating # of required reducers.\n",
      "2024-01-29 17:08:11,461 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Setting Parallelism to 1\n",
      "2024-01-29 17:08:11,461 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Setting up single store job\n",
      "2024-01-29 17:08:11,469 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 1 map-reduce job(s) waiting for submission.\n",
      "2024-01-29 17:08:11,470 [JobControl] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-01-29 17:08:11,474 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
      "2024-01-29 17:08:11,475 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2024-01-29 17:08:11,475 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths to process : 1\n",
      "2024-01-29 17:08:11,475 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths (combined) to process : 1\n",
      "2024-01-29 17:08:11,476 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1\n",
      "2024-01-29 17:08:11,481 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local389593575_0005\n",
      "2024-01-29 17:08:11,481 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Executing with tokens: []\n",
      "2024-01-29 17:08:11,529 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/\n",
      "2024-01-29 17:08:11,530 [Thread-39] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null\n",
      "2024-01-29 17:08:11,533 [Thread-39] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces\n",
      "2024-01-29 17:08:11,533 [Thread-39] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address\n",
      "2024-01-29 17:08:11,533 [Thread-39] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.reduce.markreset.buffer.percent is deprecated. Instead, use mapreduce.reduce.markreset.buffer.percent\n",
      "2024-01-29 17:08:11,533 [Thread-39] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-01-29 17:08:11,533 [Thread-39] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-01-29 17:08:11,534 [Thread-39] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigOutputCommitter\n",
      "2024-01-29 17:08:11,537 [Thread-39] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks\n",
      "2024-01-29 17:08:11,537 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local389593575_0005_m_000000_0\n",
      "2024-01-29 17:08:11,541 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-01-29 17:08:11,541 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-01-29 17:08:11,542 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2024-01-29 17:08:11,542 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Processing split: Number of splits :1\n",
      "Total Length = 90\n",
      "Input split[0]:\n",
      "   Length = 90\n",
      "   ClassName: org.apache.hadoop.mapreduce.lib.input.FileSplit\n",
      "   Locations:\n",
      "\n",
      "-----------------------\n",
      "\n",
      "2024-01-29 17:08:11,543 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigRecordReader - Current split being processed file:/tmp/temp-679547720/tmp-242619885/part-r-00000:0+90\n",
      "2024-01-29 17:08:11,546 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)\n",
      "2024-01-29 17:08:11,546 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100\n",
      "2024-01-29 17:08:11,546 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - soft limit at 83886080\n",
      "2024-01-29 17:08:11,546 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600\n",
      "2024-01-29 17:08:11,546 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600\n",
      "2024-01-29 17:08:11,547 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "2024-01-29 17:08:11,547 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.impl.util.SpillableMemoryManager - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128\n",
      "2024-01-29 17:08:11,547 [LocalJobRunner Map Task Executor #0] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\n",
      "2024-01-29 17:08:11,548 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigGenericMapReduce$Map - Aliases being processed per job phase (AliasName[line,offset]): M: top5[37,7] C:  R: \n",
      "2024-01-29 17:08:11,548 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - \n",
      "2024-01-29 17:08:11,548 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Starting flush of map output\n",
      "2024-01-29 17:08:11,548 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Spilling map output\n",
      "2024-01-29 17:08:11,548 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 90; bufvoid = 104857600\n",
      "2024-01-29 17:08:11,548 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214380(104857520); length = 17/6553600\n",
      "2024-01-29 17:08:11,550 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Finished spill 0\n",
      "2024-01-29 17:08:11,551 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local389593575_0005_m_000000_0 is done. And is in the process of committing\n",
      "2024-01-29 17:08:11,551 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - map\n",
      "2024-01-29 17:08:11,551 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local389593575_0005_m_000000_0' done.\n",
      "2024-01-29 17:08:11,551 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local389593575_0005_m_000000_0: Counters: 17\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=72108078\n",
      "\t\tFILE: Number of bytes written=3100596\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=5\n",
      "\t\tMap output records=5\n",
      "\t\tMap output bytes=90\n",
      "\t\tMap output materialized bytes=106\n",
      "\t\tInput split bytes=378\n",
      "\t\tCombine input records=0\n",
      "\t\tSpilled Records=5\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=696254464\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=0\n",
      "2024-01-29 17:08:11,552 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local389593575_0005_m_000000_0\n",
      "2024-01-29 17:08:11,552 [Thread-39] INFO  org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.\n",
      "2024-01-29 17:08:11,552 [Thread-39] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks\n",
      "2024-01-29 17:08:11,552 [pool-18-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local389593575_0005_r_000000_0\n",
      "2024-01-29 17:08:11,556 [pool-18-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-01-29 17:08:11,556 [pool-18-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-01-29 17:08:11,557 [pool-18-thread-1] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2024-01-29 17:08:11,557 [pool-18-thread-1] INFO  org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@7ea5088b\n",
      "2024-01-29 17:08:11,557 [pool-18-thread-1] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-01-29 17:08:11,558 [pool-18-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=652528832, maxSingleShuffleLimit=163132208, mergeThreshold=430669056, ioSortFactor=10, memToMemMergeOutputsThreshold=10\n",
      "2024-01-29 17:08:11,558 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local389593575_0005_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events\n",
      "2024-01-29 17:08:11,559 [localfetcher#5] INFO  org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#5 about to shuffle output of map attempt_local389593575_0005_m_000000_0 decomp: 102 len: 106 to MEMORY\n",
      "2024-01-29 17:08:11,559 [localfetcher#5] INFO  org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 102 bytes from map-output for attempt_local389593575_0005_m_000000_0\n",
      "2024-01-29 17:08:11,559 [localfetcher#5] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 102, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->102\n",
      "2024-01-29 17:08:11,560 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning\n",
      "2024-01-29 17:08:11,560 [pool-18-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2024-01-29 17:08:11,560 [pool-18-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs\n",
      "2024-01-29 17:08:11,561 [pool-18-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 1 sorted segments\n",
      "2024-01-29 17:08:11,561 [pool-18-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 90 bytes\n",
      "2024-01-29 17:08:11,562 [pool-18-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 102 bytes to disk to satisfy reduce memory limit\n",
      "2024-01-29 17:08:11,562 [pool-18-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 106 bytes from disk\n",
      "2024-01-29 17:08:11,562 [pool-18-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce\n",
      "2024-01-29 17:08:11,562 [pool-18-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 1 sorted segments\n",
      "2024-01-29 17:08:11,562 [pool-18-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 90 bytes\n",
      "2024-01-29 17:08:11,562 [pool-18-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2024-01-29 17:08:11,563 [pool-18-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-01-29 17:08:11,563 [pool-18-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-01-29 17:08:11,565 [pool-18-thread-1] INFO  org.apache.pig.impl.util.SpillableMemoryManager - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128\n",
      "2024-01-29 17:08:11,565 [pool-18-thread-1] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\n",
      "2024-01-29 17:08:11,566 [pool-18-thread-1] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigMapReduce$Reduce - Aliases being processed per job phase (AliasName[line,offset]): M: top5[37,7] C:  R: \n",
      "2024-01-29 17:08:11,566 [pool-18-thread-1] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local389593575_0005_r_000000_0 is done. And is in the process of committing\n",
      "2024-01-29 17:08:11,568 [pool-18-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2024-01-29 17:08:11,568 [pool-18-thread-1] INFO  org.apache.hadoop.mapred.Task - Task attempt_local389593575_0005_r_000000_0 is allowed to commit now\n",
      "2024-01-29 17:08:11,569 [pool-18-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local389593575_0005_r_000000_0' to file:/tmp/temp-679547720/tmp-7358545\n",
      "2024-01-29 17:08:11,569 [pool-18-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce\n",
      "2024-01-29 17:08:11,569 [pool-18-thread-1] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local389593575_0005_r_000000_0' done.\n",
      "2024-01-29 17:08:11,569 [pool-18-thread-1] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local389593575_0005_r_000000_0: Counters: 24\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=72108322\n",
      "\t\tFILE: Number of bytes written=3100804\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=5\n",
      "\t\tReduce shuffle bytes=106\n",
      "\t\tReduce input records=5\n",
      "\t\tReduce output records=5\n",
      "\t\tSpilled Records=5\n",
      "\t\tShuffled Maps =1\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=1\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=696254464\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=0\n",
      "2024-01-29 17:08:11,569 [pool-18-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local389593575_0005_r_000000_0\n",
      "2024-01-29 17:08:11,570 [Thread-39] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-29 17:08:11,730 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - HadoopJobId: job_local389593575_0005\n",
      "2024-01-29 17:08:11,730 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - Processing aliases top5\n",
      "2024-01-29 17:08:11,730 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - detailed locations: M: top5[37,7] C:  R: \n",
      "2024-01-29 17:08:11,732 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-01-29 17:08:11,733 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-01-29 17:08:11,734 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-01-29 17:08:11,737 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 100% complete\n",
      "2024-01-29 17:08:11,741 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.SimplePigStats - Script Statistics: \n",
      "\n",
      "HadoopVersion\tPigVersion\tUserId\tStartedAt\tFinishedAt\tFeatures\n",
      "3.3.1\t0.17.0\troot\t2024-01-29 17:08:00\t2024-01-29 17:08:11\tHASH_JOIN,GROUP_BY,ORDER_BY,FILTER,LIMIT\n",
      "\n",
      "Success!\n",
      "\n",
      "Job Stats (time in seconds):\n",
      "JobId\tMaps\tReduces\tMaxMapTime\tMinMapTime\tAvgMapTime\tMedianMapTime\tMaxReduceTime\tMinReduceTime\tAvgReduceTime\tMedianReducetime\tAlias\tFeature\tOutputs\n",
      "job_local1232131069_0003\t1\t1\tn/a\tn/a\tn/a\tn/a\tn/a\tn/a\tn/a\tn/a\ttop5\tSAMPLER\t\n",
      "job_local346672689_0002\t2\t1\tn/a\tn/a\tn/a\tn/a\tn/a\tn/a\tn/a\tn/a\trecover\tHASH_JOIN\t\n",
      "job_local389593575_0005\t1\t1\tn/a\tn/a\tn/a\tn/a\tn/a\tn/a\tn/a\tn/a\ttop5\t\tfile:/tmp/temp-679547720/tmp-7358545,\n",
      "job_local533391016_0001\t3\t1\tn/a\tn/a\tn/a\tn/a\tn/a\tn/a\tn/a\tn/a\tFLIGHTS,contar_recuperados,contar_retrasos,total_recuperados,total_retrasos,vuelos_recuperados,vuelos_retrasados\tMULTI_QUERY,COMBINER\t\n",
      "job_local856459684_0004\t1\t1\tn/a\tn/a\tn/a\tn/a\tn/a\tn/a\tn/a\tn/a\ttop5\tORDER_BY,COMBINER\t\n",
      "\n",
      "Input(s):\n",
      "Successfully read 2702218 records from: \"file:///media/notebooks/flights.csv\"\n",
      "\n",
      "Output(s):\n",
      "Successfully stored 5 records in: \"file:/tmp/temp-679547720/tmp-7358545\"\n",
      "\n",
      "Counters:\n",
      "Total records written : 5\n",
      "Total bytes written : 0\n",
      "Spillable Memory Manager spill count : 0\n",
      "Total bags proactively spilled: 0\n",
      "Total records proactively spilled: 0\n",
      "\n",
      "Job DAG:\n",
      "job_local533391016_0001\t->\tjob_local346672689_0002,\n",
      "job_local346672689_0002\t->\tjob_local1232131069_0003,\n",
      "job_local1232131069_0003\t->\tjob_local856459684_0004,\n",
      "job_local856459684_0004\t->\tjob_local389593575_0005,\n",
      "job_local389593575_0005\n",
      "\n",
      "\n",
      "2024-01-29 17:08:11,742 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-01-29 17:08:11,743 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-01-29 17:08:11,744 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-01-29 17:08:11,747 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-01-29 17:08:11,748 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-01-29 17:08:11,749 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-01-29 17:08:11,751 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-01-29 17:08:11,751 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-01-29 17:08:11,752 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-01-29 17:08:11,754 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-01-29 17:08:11,754 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-01-29 17:08:11,755 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-01-29 17:08:11,757 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-01-29 17:08:11,757 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-01-29 17:08:11,758 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-01-29 17:08:11,759 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - Success!\n",
      "2024-01-29 17:08:11,761 [main] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\n",
      "2024-01-29 17:08:11,762 [main] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2024-01-29 17:08:11,762 [main] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths to process : 1\n",
      "(UA,0.24507301133462678)\n",
      "(WN,0.23570878543927196)\n",
      "(FL,0.2265728843597696)\n",
      "(DL,0.21578780710414067)\n",
      "(AA,0.20162014676224854)\n",
      "2024-01-29 17:08:11,825 [main] INFO  org.apache.pig.Main - Pig script completed in 12 seconds and 66 milliseconds (12066 ms)\n"
     ]
    }
   ],
   "source": [
    "! pig -x local -f company_recover.pig -param airports_file='airports.csv' -param flights_file='flights.csv' -param output_dir='pig/output/flights'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
